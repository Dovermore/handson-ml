{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 14 â€“ Recurrent Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 14._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T04:33:25.799892Z",
     "start_time": "2018-03-11T04:33:25.171969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then of course we will need TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T04:33:28.281910Z",
     "start_time": "2018-03-11T04:33:28.278458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t = 0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `static_rnn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"b<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs,\n",
    "                                                dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.transpose(outputs_val, axes=[1, 0, 2])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `dynamic_rnn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # step 0     step 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2 (padded with zero vectors)\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a sequence classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function. The main differences relevant to this chapter are:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T21:41:01.811461Z",
     "start_time": "2018-03-08T21:40:58.321781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                          logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T21:41:06.219967Z",
     "start_time": "2018-03-08T21:41:02.825994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T22:15:58.177091Z",
     "start_time": "2018-03-08T21:41:08.749299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.93333334 Test accuracy: 0.923\n",
      "1 Train accuracy: 0.9533333 Test accuracy: 0.9533\n",
      "2 Train accuracy: 0.94666666 Test accuracy: 0.9551\n",
      "3 Train accuracy: 0.98 Test accuracy: 0.948\n",
      "4 Train accuracy: 0.94 Test accuracy: 0.9602\n",
      "5 Train accuracy: 0.98 Test accuracy: 0.9674\n",
      "6 Train accuracy: 0.9866667 Test accuracy: 0.9686\n",
      "7 Train accuracy: 0.97333336 Test accuracy: 0.971\n",
      "8 Train accuracy: 0.96666664 Test accuracy: 0.9721\n",
      "9 Train accuracy: 0.96 Test accuracy: 0.9671\n",
      "10 Train accuracy: 0.98 Test accuracy: 0.9724\n",
      "11 Train accuracy: 0.96666664 Test accuracy: 0.9698\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.9705\n",
      "13 Train accuracy: 0.9866667 Test accuracy: 0.9731\n",
      "14 Train accuracy: 0.9866667 Test accuracy: 0.9787\n",
      "15 Train accuracy: 0.9866667 Test accuracy: 0.9713\n",
      "16 Train accuracy: 0.9866667 Test accuracy: 0.9742\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9743\n",
      "18 Train accuracy: 0.96666664 Test accuracy: 0.9737\n",
      "19 Train accuracy: 0.98 Test accuracy: 0.9797\n",
      "20 Train accuracy: 0.9866667 Test accuracy: 0.9734\n",
      "21 Train accuracy: 0.98 Test accuracy: 0.9788\n",
      "22 Train accuracy: 0.96666664 Test accuracy: 0.9752\n",
      "23 Train accuracy: 0.98 Test accuracy: 0.9741\n",
      "24 Train accuracy: 0.99333334 Test accuracy: 0.9691\n",
      "25 Train accuracy: 0.99333334 Test accuracy: 0.9774\n",
      "26 Train accuracy: 0.98 Test accuracy: 0.9794\n",
      "27 Train accuracy: 0.99333334 Test accuracy: 0.9748\n",
      "28 Train accuracy: 0.96666664 Test accuracy: 0.9783\n",
      "29 Train accuracy: 0.97333336 Test accuracy: 0.9771\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.9817\n",
      "31 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
      "32 Train accuracy: 0.98 Test accuracy: 0.9782\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.9774\n",
      "34 Train accuracy: 0.99333334 Test accuracy: 0.9798\n",
      "35 Train accuracy: 0.99333334 Test accuracy: 0.9698\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9787\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.9744\n",
      "38 Train accuracy: 0.9866667 Test accuracy: 0.9744\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.9781\n",
      "41 Train accuracy: 0.98 Test accuracy: 0.9795\n",
      "42 Train accuracy: 0.9866667 Test accuracy: 0.9824\n",
      "43 Train accuracy: 1.0 Test accuracy: 0.9703\n",
      "44 Train accuracy: 0.9866667 Test accuracy: 0.9816\n",
      "45 Train accuracy: 1.0 Test accuracy: 0.979\n",
      "46 Train accuracy: 0.99333334 Test accuracy: 0.9796\n",
      "47 Train accuracy: 1.0 Test accuracy: 0.981\n",
      "48 Train accuracy: 0.99333334 Test accuracy: 0.9811\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9792\n",
      "50 Train accuracy: 1.0 Test accuracy: 0.9772\n",
      "51 Train accuracy: 0.99333334 Test accuracy: 0.9782\n",
      "52 Train accuracy: 0.99333334 Test accuracy: 0.9796\n",
      "53 Train accuracy: 1.0 Test accuracy: 0.9758\n",
      "54 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
      "55 Train accuracy: 0.99333334 Test accuracy: 0.9798\n",
      "56 Train accuracy: 0.99333334 Test accuracy: 0.9818\n",
      "57 Train accuracy: 0.99333334 Test accuracy: 0.9798\n",
      "58 Train accuracy: 0.9866667 Test accuracy: 0.9806\n",
      "59 Train accuracy: 0.98 Test accuracy: 0.9729\n",
      "60 Train accuracy: 0.99333334 Test accuracy: 0.9784\n",
      "61 Train accuracy: 0.99333334 Test accuracy: 0.9802\n",
      "62 Train accuracy: 0.99333334 Test accuracy: 0.9785\n",
      "63 Train accuracy: 1.0 Test accuracy: 0.9806\n",
      "64 Train accuracy: 1.0 Test accuracy: 0.9743\n",
      "65 Train accuracy: 0.99333334 Test accuracy: 0.9804\n",
      "66 Train accuracy: 1.0 Test accuracy: 0.9784\n",
      "67 Train accuracy: 0.99333334 Test accuracy: 0.9801\n",
      "68 Train accuracy: 0.99333334 Test accuracy: 0.9773\n",
      "69 Train accuracy: 0.99333334 Test accuracy: 0.9782\n",
      "70 Train accuracy: 0.98 Test accuracy: 0.9767\n",
      "71 Train accuracy: 1.0 Test accuracy: 0.979\n",
      "72 Train accuracy: 0.99333334 Test accuracy: 0.9813\n",
      "73 Train accuracy: 0.99333334 Test accuracy: 0.977\n",
      "74 Train accuracy: 0.9866667 Test accuracy: 0.9745\n",
      "75 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
      "76 Train accuracy: 0.99333334 Test accuracy: 0.9791\n",
      "77 Train accuracy: 0.9866667 Test accuracy: 0.9644\n",
      "78 Train accuracy: 0.99333334 Test accuracy: 0.9763\n",
      "79 Train accuracy: 0.9866667 Test accuracy: 0.977\n",
      "80 Train accuracy: 0.9866667 Test accuracy: 0.981\n",
      "81 Train accuracy: 1.0 Test accuracy: 0.9795\n",
      "82 Train accuracy: 0.99333334 Test accuracy: 0.9735\n",
      "83 Train accuracy: 1.0 Test accuracy: 0.9761\n",
      "84 Train accuracy: 0.98 Test accuracy: 0.9758\n",
      "85 Train accuracy: 1.0 Test accuracy: 0.9812\n",
      "86 Train accuracy: 0.9866667 Test accuracy: 0.9791\n",
      "87 Train accuracy: 0.97333336 Test accuracy: 0.9748\n",
      "88 Train accuracy: 0.99333334 Test accuracy: 0.9735\n",
      "89 Train accuracy: 1.0 Test accuracy: 0.9748\n",
      "90 Train accuracy: 1.0 Test accuracy: 0.9791\n",
      "91 Train accuracy: 1.0 Test accuracy: 0.9776\n",
      "92 Train accuracy: 0.9866667 Test accuracy: 0.9789\n",
      "93 Train accuracy: 1.0 Test accuracy: 0.9767\n",
      "94 Train accuracy: 1.0 Test accuracy: 0.9811\n",
      "95 Train accuracy: 1.0 Test accuracy: 0.9784\n",
      "96 Train accuracy: 1.0 Test accuracy: 0.9792\n",
      "97 Train accuracy: 0.9866667 Test accuracy: 0.9757\n",
      "98 Train accuracy: 0.99333334 Test accuracy: 0.9779\n",
      "99 Train accuracy: 0.99333334 Test accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T03:22:03.853722Z",
     "start_time": "2018-03-09T03:22:03.733323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T03:22:32.225954Z",
     "start_time": "2018-03-09T03:22:31.777755Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,\n",
    "                                      activation=tf.nn.relu)\n",
    "          for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T03:22:35.329203Z",
     "start_time": "2018-03-09T03:22:34.049510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_concat = tf.concat(axis=1, values=states)\n",
    "logits = tf.layers.dense(states_concat, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T05:13:42.473731Z",
     "start_time": "2018-03-09T05:09:43.192598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.96666664 Test accuracy: 0.9481\n",
      "1 Train accuracy: 0.9866667 Test accuracy: 0.9644\n",
      "2 Train accuracy: 0.96 Test accuracy: 0.9634\n",
      "3 Train accuracy: 0.9866667 Test accuracy: 0.9712\n",
      "4 Train accuracy: 0.9533333 Test accuracy: 0.9622\n",
      "5 Train accuracy: 0.99333334 Test accuracy: 0.9792\n",
      "6 Train accuracy: 0.99333334 Test accuracy: 0.9724\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9795\n",
      "8 Train accuracy: 1.0 Test accuracy: 0.9787\n",
      "9 Train accuracy: 0.9866667 Test accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T04:34:09.502293Z",
     "start_time": "2018-03-11T04:34:09.473597Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T04:34:14.657772Z",
     "start_time": "2018-03-11T04:34:12.198290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure time_series_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAEYCAYAAADMNRC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXd8HPWd//98r7q0q94l27LlKtwI\nNhhMM6GGHuDS4EIgRzh+yeVykMDlkm+4kNxdElIucRLSk0tIgwRCEgyJAZtimg1uuMuWbclW712r\n/fz+mFlpJa1Wa6vMSvt+Ph772N2Zz8y8dyzPzOvzbmKMQVEURVEURVEUJRxcThugKIqiKIqiKMr0\nQQWEoiiKoiiKoihhowJCURRFURRFUZSwUQGhKIqiKIqiKErYqIBQFEVRFEVRFCVsVEAoiqIoiqIo\nihI2KiCUKUdEjIjc7LQdE4WIPCgiu6fgOLeLyPOTfZzpiohk239bF9vfl4lIlYikOGyaoigRhIj8\nXET+corbbBKR9ZNlU8BxpuR+oijjRbQPhBIuInImsBV4zRizNozxPweyjTHXDFueDzQZY3omxdAp\nRkTcQIIxpmESjxEPHAY+ZIzZPFnHmWrsh/0XgBxjTP0495UN1AHrjDGb7GV/ALYbYx4ap6mKokwQ\nE3UvGcfx07Cef5pPYZtMoM8Y0zYRNoQ4zoTeT0TkdmC9McY9EftTFD/qgVBOhX8CvgcsFZElp7sT\nY0z1TBAPIuISkRhjTPtkigebm4Hu6SIebMETCfwM+GcRiXXaEEVRBpiQe8lwRCQunHHGmJZTEQ/2\nNo2TLR7s40zF/URRxo0KCCUsRCQJ+CDwI+Bx4M4xxj8IfBi42g4rCQwtGQhhEpES+/v7RWSziHSJ\nyNsislxElorIFhHpEJGXRWTusGNcKyLbRKRbRI6IyJdDPbiKSJqI/FJEau1tDovIvw5b/0N7fZtt\nz6qA9beLSLuIvMd2MfcCS4K5nEXkIyKyxz7OARH5lIi4AtZ/zF7eLSJ1IvLsGA+5HwSeGnaMWBH5\npog02a9visj3RWRTwBgRkc+ISLl9bneJyK0B6/3n/yYR+buIdNp2XzbsWGUi8lf7vNSKyG9sT5J/\n/c9F5C8icr+IVAKV9vJbReTNgO0eE5Ei/7GxvA8AdbYdPw/HbnvM6oB//7eBc4Kct78BmcDFIc6t\noihTxETdSwKuXR8QkedFpAv4mIhk2denSvva8Y6IfGTYPoeEMIkVnvQ9EfkvEam3r1UPD7tmDwlh\nEpEKEfmciPxARFrt43162HEW2veRbhHZb9872sXyCoz6ewPvJwHX1k+KFZLZJCI/E5HkgDEXishr\n9r5bROR1se6fF2NNoqQEnLsH7W1GvTbb6y+2x7/b3l+niGwVkXcNs3eNff477GM/JyKF9roxr+PK\nNMYYoy99jfkCbgN22J8vBmqBuBDj3cDvgL8D+fYr3l5ngJvtzyX29/3Ae4DFWA+Vu+33dcAZWO7u\nPwfs/wqgFfgIUGqP2w88HMKm7wDbgbPt414M3GKvE+Bl4K/2+vnAQ/YxCuwxtwNeYAuwFlgIeIAH\ngd0Bx/kn4CSW12AucC1QDXzcXr/K3s+HgDnACuBTQGwI25uBDw5b9gDQBNwELAL+F2gBNgWM+bJ9\nXq60bfkg0AFcPez877PtXAD8AmgA3PaYAqAe+AqwBFgO/Bl4A3DZY34OtAGPAkuBZfbyO+x/13n2\neX0BeNFeFwO81z5+GdbfSFqYdqdg/Q0+Zh/vCmCvva+Lh52n14CHnP4/pC996Wvi7iUB166KgGtt\nMVAEfBpYaV937sKa7Hl3wD5/Dvwl4Psm+9r5Razr+j/Y1+gPDBuzPuB7hX2d/DjW/eITtj3n2utd\nwDvAc7Yt5wKvA33A7SF+74MMvZ/83LbtR/b193Ks+8G/2+tjse4DD2PdCxfb18sl9nn6pH3t9J87\n/3V91GtzwL+NwbrOr7P3+6x9nfWHv68AuoAf2r9xCfAxYLa9PuR1XF/T++W4AfqaHi9gM3Cf/Vns\ni+dNY2wz5CIdsDyYgPhYwPpr7GXvDVh2O9Ae8P1F4PPD9nsD0O6/uAU57lPAz0ZZd4m9bdKw5duB\nzwTYYICzho0ZfsE/Btw2bMy/Anvsz++1bwieMM99un3cdcOWnwQeCPguWEJgk/09xb64XzBsu28B\nT4c4/0X2svPt718Enhu2jwx7zNkB/9Z1WLG7oX7LYnu7Yvv7xfb37IAx4dh9F9ZN1B2w/laCC4g/\nAr90+v+QvvSlr4m7lwRcu+4N45i/BX482v6wxMGrw7b5+7BtNjFSQPxm2DYHgc/Zn6/AEiFFAevP\ns22+PYStDzJSQBwnYIIJS0xstD9n2vu8aJT93U7AvTPEcUe7Nl8RMGbtsDGPYuWxBNvfmNdxfU3v\nl8YFK2MiIvOxLhwfADDGGBF5FPgo8IcJOszOgM819vuuYctSRCTZGNMJnAWcLSL3B4xxAUlYsywn\ngxzj+8Djtgv271geDX9OwVlAMlYoTeA2iVizOn68WKIiKCKSA8wCfiAi3w9YFYt1s8Q+9lHgiIg8\nixVm80czenxtkv3eHXCcNPt3vuFfZv+7vGkfH6xZ/UTgGRExAfuLw7r5BRJ4/k/Y77n2+1nAhSLS\nHsS20gAbdpthuS32uf4C1uxUJoPnYDZ2mFMQwrF7CbDTGBNo06uj7K+LwXOoKIpDTNK9ZOuwY8Rg\neWffhzUZkoA1E79pjP3sHPb9BIPXwNPZZjFwwhhTFbD+TcA3xj6DsccY4x12nHPAys2wQz+fFZHn\nsDwejxljjofa4Slcm0e7N1QCZwJPjHKIU7n/KNMQFRBKOHwUK9zkWMDDtQCIyKyxLlRh0hfw2YRY\n5gp4/0+sEJbh1AU7gDFmg4jMAa4C3g38VUQeM8Z8xN5fDXBBkE1bAz73GGP6Q/wOv313Y4U6BbOj\nzb54XwhcBvw78F8istoYcyLIJg1Yvz8j2O7CsOVaLK9IIH2jfbdv6oHbu7BCu+4LcoyagM8dgSvE\nKp/6LLARK2yhFsgGXsK6oY/HbiF8MtEblqJEApNxL+kY9v0+4F6s0J1dWJ7l/2JsMTD8mmgYO080\n1DZC6OvzqRDSNmPMR0TkW1ihQtcBXxaRG4wxzwbb2Slem0Pdh0Ndh0/l/qNMQ1RAKCERK7H3w1gP\nucPrZv8SKwfhi6Ns3ot1s5gM3gIWG2MOncpGxioV+kvglyKyAfiNiNxt7y8P8BljDp+uUcaYGhGp\nAkqNMf8XYpwXeB54XkS+gHUBvwYrlnT42F4R2YM1o/O0vaxFRKoZjF1FrDvyaqx8C4A9QA8wxxgz\nnv4Rb2HFBB81xpzKhX8x1k3ps8aYI7aN7x02ptd+D/w7CcfuPcCHRSTFGON/gFgzytilWGFMiqI4\nxBTeS87H8i7/0j6uYOU1nFLVpQlgL1AkIoUBE0OrmKTiNcaYHcAO4Cv2ve3DWCIh2LkL59ocDm9h\nhf8GY6LuP0qEogJCGYursS40PzLDSsuJyG+xSmR+yRgTzC1bAVwlIouwZtFbTvEBNBRfBP4iIkeB\n32OFFi3Fisn/TLANROSLWBe8d7D+9t8LHDbG9IjIRuAV4E8i8hmsXIJ8rBmdjcaYl07BtgeB74hI\nM9YDfxzwLqxY2P8WkWuwQn9eBBqxEtQ8WDec0XgW68b4cMCy/wU+IyIHsC7WH8NKeD4JA56Oh4GH\n7Zvoi1gJiWuwhNIIsTIK38VKDP+diHwFy8MzD0tU3Bsi9OoY1g3k4yLyXaywo+H9GI5izWpdLSJ/\nBrrCtPvXWAl6P7X/XQuB/xhugFiVnoqwwsQURXGOCb2XhDjOAeB9InI+VvGHT2Al8L49/p9wSvwd\nK4H4FyJyH1YY5Tew7lUT5ZlArOqEH8PK8avCujYvxwrZBevcJYpVWe9toJPwrs3h8DXgNRH5IdZ9\nohvLi/83Y8yxCbr/KBGKlnFVxuJO4IXhF3ybx7CqCF06yrY/wnoo3or10Dlmw6BwsV2zV2M9fL9h\nvx5gpKs0kB6sh84dWGLBg+VexRhjsCpSPG/bvR9LmCxiMO4zXNt+jFXh4jb7WC9hJf0esYc0YyV8\nb8QSKvcBHx1DpPwIuFKsZkZ+HsaaufsZVqUhsOJRuwPGfB5L0NyHJZz+jlW16QhhYs+ercWK3X3G\n3s93sc7nqP08jDF1WLNgN2AJnC8A/zZsTJW9/MtY4VD+Mokh7bZzH67Bqhr1Fta5CMyH8fMBrJvZ\n0XB/r6Iok8JU3Uu+hHU/2ID10NqBlew7pdhC6EasHIw3sKrbfRlLPHSH2PRU6cTysDyGJZ5+gfV7\nv2LbsQV4BPgN1rn7TDjX5nAwxmzH+jdbjHUPeh14P4MhSuO+/yiRi3aiVpRpgj1L944J0VVZRN4C\nXjHGfGLqLItMRCQBqyrKB4wxrzhtj6Io0Y2IrMAqwrHKGLPNaXsUZTxoCJOiTB8+gzWjBYCdEH4F\nVlnEWCwvxwr7XbFmNL+s4kFRFCcQkRuxPCAHscrOfgPLK/2Wg2YpyoSgHghFmaaIyCwst/QyrHDE\nPVi9MTTeX1EUxWFE5B+Bz2GV1m7CKiX7KWNMTajtFGU6oAJCURRFURRFUZSw0SRqRVEURVEURVHC\nJipyILKzs01JSYnTZiiKokxLtm3bVm+MyXHajnDQ672iKMrpE+71PioERElJCVu3bh17oKIoijIC\nu9/KtECv94qiKKdPuNd7DWFSFEVRFEVRFCVsVEAoiqIoiqIoihI2KiAURVEURVEURQmbqMiBUBRF\nUaKXvr4+Kisr6e7udtqUaUViYiLFxcXExcU5bYqiTAvKy+HrX4ennoLvfAc+8Qm47jq4914oLZ28\nbZ1ABYSiKIoyo6msrMTj8VBSUoKIOG3OtMAYQ0NDA5WVlcydO9dpcxQl4tmwAW6+Gfr64H3vgxtv\nhD/8AX78Y/jFL+Dxx+GqqyZ+W6fQECZFURRlRtPd3U1WVpaKh1NARMjKylKvjaKEQXm5JQA6Oy0R\ncMcd1vI77rC+d3Za68vLJ3ZbJ1EPhKIoijLjUfFw6ug5U5Tw6O2Fjo7B7z091vvatWDM4PJ9+yZ2\nWydRD4SiKIqi2JSXwz33QGoquFzW+z33RN7sn6IokcN99w0VAQkJQ9/BWn/vvRO7rZOogFAURVEU\nrDjk5cutuOO2Nmv2r63N+r58ubX+dDnvvPNOa7snn3ySPXv2nP6BFUWZdDZsgGuuGSoEAunogKuv\nhmeemdhtnUQFhKIoihL1DI9DDmQi4pC3bNlyWtupgFCUyMfthk2brATorq6h67q6rOWbN1vjJnJb\nJ1EBoSiKokQ9X//6SOEwnL4++OY3T2//bvvuv2nTJi6++GJuvvlmFi9ezIc+9CGMHej8wAMPUFZW\nxvLly7nvvvvYsmULTz31FJ/+9KdZuXIl5eXl/OhHP2L16tWsWLGCm266ic7OTgBuv/12/uVf/oXz\nzjuPefPm8fjjjw8c+6tf/SrLli1jxYoVPPDAAwCUl5dz5ZVXctZZZ3HBBRewL9ICrBVlGnHrrRAX\nB+np4PVar87Owc/p6db6226b2G0dxRgz419nnXWWURRFUU4PYKuJgGt5OK9g1/s9e/aM+Rs9HmOs\noKXQr9TU8M9bICkpKcYYY1544QWTmppqjh8/bvr7+82aNWvMSy+9ZBoaGszChQuNz+czxhjT1NRk\njDHmwx/+sHnssccG9lNfXz/w+T/+4z/Mt7/97YFxN998s+nv7zfvvPOOKS0tNcYY8/TTT5tzzz3X\ndHR0GGOMaWhoMMYYc8kll5gDBw4YY4x57bXXzLp164LaHc65U5Ro59AhY5KTjXn+eWO8XmO2bTPm\n0kutd6/XmOees9YfOjSx204G4V7vtQqToihKhLD3ZCudvV7OmpPptClRR3v7xI4Lxdlnn01xcTEA\nK1eupKKigjVr1pCYmMhHP/pRrr76aq655pqg2+7evZvPfe5zNDc3097ezhVXXDGw7oYbbsDlclFW\nVkZNTQ0AGzdu5CMf+QjJyckAZGZm0t7ezpYtW7jlllsGtu3xl35RFOWUKS21ejW0t8P998M3vmFN\nOaxeDf/2b3Dhhdb6YA3hxrOtk2gIk6IoSgTg8xnu/tU23veD13hhX63T5kQd4cYXT0QcckJAeZWY\nmBi8Xi+xsbG88cYb3HTTTTz55JNceeWVQbe9/fbbWb9+Pbt27eILX/jCkD4Ngfs1dliUMWZEOVaf\nz0d6ejrbt28feO3du3f8P0xRopirroKyMujuBo/HquLmdlt5DGVloRvBjWdbp1ABoSiKEgG8driB\now2dJMfHcN9jO/D5zNgbKROGPw45FJMZh9ze3k5LSwvvec97+Na3vsX27dsB8Hg8tLW1DYxra2uj\noKCAvr4+Hn300TH3e/nll/PTn/50IFeisbGR1NRU5s6dy2OPPQZYImPHjh2T8KsUZfrhL+VcXAxP\nPGG9h1vKubQU1q+Hlhbo77fe168Pz3swnm2dQAWEoihKBPDbN4+TmhjLp69YRENHL4frR6npp0wK\n994bnoD41Kcm5/htbW1cc801LF++nIsuuohv2tna73//+/na177GmWeeSXl5OQ899BDnnHMOl112\nGYsXLx5zv1deeSXXXXcdq1atYuXKlTz88MMAPProo/zkJz9hxYoVnHHGGfzpT3+anB+mKNOIwFLO\n69bBjTfCxRdPTCnnmYb43ZyRhIh8HLgdWAb8xhhze8C6dwPfBWYDrwO3G2OOhtrfqlWrzNatWyfN\nXkVRlPFgjOGsL23kksW53H3RPC79xot89ebl/MOqWU6bBoCIbDPGrHLajnAIdr3fu3cvS5YsGXPb\nDRusUq19fUMrMsXFWa/HH4/MUILJJNxzpyjTnfJySyTYzjqef94SEc8/D+9+t7UsORl27oxcr8BE\nEO71PlI9ECeALwE/DVwoItnAH4HPA5nAVuB3U26doijKBFLX3kNjRy9lBanMy3aTlhTHW0ebnDYr\nIhCR94vIXhHpEJFyEblgso511VXWw8Fddw3tRH3XXdbyaBMPihJN9PZaTdv8Ndf8vR/Xrh1c1tEx\ndrnnaCEiBYQx5o/GmCeBhmGr3gu8Y4x5zBjTDTwIrBCRsf24iqIoEcr+aivGfXGBB5dLOHN2Om8d\nUwEhIpcBXwE+AniAC4HDk3nM6RaHrCjKxHDffUO7QftrEgTUJqCjwwp3VCJUQITgDGAg08sY0wGU\n28sVRVGmJQMCIj8VgDNnZXCgpp2OHq+TZkUC/wl80RjzmjHGZ4ypMsZUOW2Uoigzjw0b4JprhoqI\nQDo64Oqr4ZlnptauSGW6CQg30DJsWQvWzNQQROQuEdkqIlvr6uqmxDhFUZTTYV91GzmeBDJT4gFY\nkGfVCj0SxYnUIhIDrAJyROSQiFSKyHoRSQoyVq/3iqKMC7cbNm2C973PKp8aSFeXtXzz5okp5TwT\nmG4Coh1IHbYsFWgbPtAY80NjzCpjzKqcnJwpMU5RFOV02F/dxuL8wXmQkqwUACoaoldAAHlAHHAz\ncAGwEjgT+NzwgXq9VxRlvPhLOaeng9drvTo7Bz+np09uKefpxnQTEO8AK/xfRCQFKLWXK4qiTDuM\nMRysbWNhXoCAyLa6BldEsQcC8M8BfscYc9IYUw98A3iPgzYpijJD8ZdyvvPOwWpL119vvScnwx13\nTG4p5+lGRAoIEYkVkUQgBogRkUQRiQWeAJaKyE32+v8H7DTG7HPSXkVRlNOlrq2H7j4fJVnJA8uS\n42PJT02M6l4QxpgmoBKIvFrjp0hzczPf+973Jv04mzZtYsuWLZN+HEWZiZSWWqWa29vh/vth1SrY\nuBFWr4YHHrByIB5/XAsq+IlIAYHlou4CHgButT9/zhhTB9wEfBloAs4B3u+UkYqiKOPleJM10V6c\nkTxkeUl2crR7IAB+BnxCRHJFJAP4V+AvDtt0ypyqgDDG4PP5Tvk4KiAUZXxcdRWUlUF3N3g8Viln\nt9vKgSgr01LOgcQ6bUAwjDEPYpVoDbZuI6BlWxVFmRFUNlldi4ozhuYGz81O4Znd1U6YFEk8BGQD\nB4Bu4PdYE0jTigceeIDy8nJWrlzJunXr2LlzJ01NTfT19fGlL32J66+/noqKCq666irWrVvHq6++\nypNPPsnGjRv5yle+QmFhIQsWLCAhIYH169dTV1fH3XffzbFjxwD41re+RVFREY888ggxMTH86le/\n4jvf+Q4XXDBpLTMUZcbiL+W8fr3TlkQ2ESkgFEVRooXKUTwQc7NTaOrso6Wzj7TkOCdMcxxjTB9w\nj/2atvzP//wPu3fvZvv27Xi9Xjo7O0lNTaW+vp41a9Zw3XXXAbB//35+9rOf8b3vfY8TJ07w0EMP\n8dZbb+HxeLjkkktYscJKAfzkJz/Jpz71Kc4//3yOHTvGFVdcwd69e7n77rtxu93cd999Tv5cRVGi\nABUQiqJMKT3efl45VE9cjIsLFmjFnMqmTrLd8STFxwxZPseuxHSkoYOVyelOmKZMAsYYPvvZz/Li\niy/icrmoqqqipqYGgDlz5rBmzRoA3njjDS666CIyMzMBuOWWWzhw4AAAGzduZM+ePQP7bG1tpa1t\nRDFCRVGUSUMFhKIoU8q//2EXf3y7irgYYdvnLyM1MTpn1/1UNnVRNMz7ADA701p2vLGTlbNUQMwU\nHn30Uerq6ti2bRtxcXGUlJTQ3d0NQEpKysA4Y0bPHff5fLz66qskJY1oiaEoijIlRGoStaIoM5C+\nfh/PvlPNGYWp9PUbXthX67RJjnO8sZNZGSMfBGf5BYSdI6FMXzwez4CHoKWlhdzcXOLi4njhhRc4\nevRo0G3OPvtsNm/eTFNTE16vlz/84Q8D6y6//HLWBwRob9++fcRxFEVRJhMVEIqiTBlvH2umo7ef\nj6+bT44ngWffie4kYZ/PUNXcNSL/AcCdEEtWSjzHG1VATHeysrJYu3YtS5cuZfv27WzdupVVq1bx\n6KOPsnhx8JogRUVFfPazn+Wcc87h0ksvpaysjLS0NAC+/e1vs3XrVpYvX05ZWRmPPPIIANdeey1P\nPPEEK1eu5KWXXpqy36coSvShIUyKokwZLx+swyVw3vxsLi/L449vVdHj7SchNmbsjWcgtW099PWb\nERWY/MzKTOaYCogZwa9//esxx+zevXvI9w9+8IPcddddeL1ebrzxRi6//HIAsrOz+d3vfjdi+4UL\nF7Jz586JMVhRFCUE6oFQFGXKeKW8gRWz0klLiuOceVl09fVzuC56ex0cH6WEq5/ZKiCimgcffJCV\nK1eydOlS5s6dyw033OC0SYqiKIB6IBRFmSKMMew72cotq2YBsCjPA8CBmjaWFKQ6aZpj+HtA+PMd\nhjM7M5m/7jqJt99HbIzO90QbDz/8sNMmKIqiBEXvSIqiTAnVrd109PZTmusGrD4HsS7hQE30Jn1W\nNlo9IIrSR/dA9PsMJ1u6p9KsGUmoqkZKcPScKdOV8nK45x4oLoYnnrDe77nHWq5MDCogFEWZEg7V\ntgNQmmOVqoyPdTEvJ4X91e1OmuUox5s6yfEkkBgXPAfE75nQMKbxkZiYSENDgz4QnwLGGBoaGkhM\nTHTaFEU5JTZsgOXL4cc/hnXr4MYb4eKLre/Ll1vrlfGjIUyKokwJ5baAmG97IAAW5nnYWdnilEmO\nU9nUFbSEq5/ZWYMCYu1UGTUDKS4uprKykrq6OqdNmVYkJiZSXFzstBmKEjbl5XDzzdBpz7ncccfg\n+6OPQl+ftX7nTigtdc7OmYAKCEVRpoTyug48ibHkuBMGli3K8/CXnSfp7PWSHB99l6PKpq6QTeLy\nUxOJixH1QIyTuLg45s6d67QZiqJMMr290BFQl6Onx3pfuxYCHZD79k2tXTMRDWFSFGVKOFTbzvxc\nNyIysGxBnuWNKK+NvkpM/T7DieauUSswAcS4hKL0JBUQiqIoYXDffUMFRELC0Hew1t9779TaNRNR\nAaEoypRQXtdOaY57yLKSbCsfoqIh+gREdWs3Xp8J2kQukFmZyVSqgFAURRmTDRvgmmuGiohAOjrg\n6qvhmWem1q6ZiAoIRVEmnc5eL7VtPcy1BYOf2VGcJOzvMD0rc3QPBGgvCEVRlHBxu2HTJnjf+6Cr\na+i6ri5r+ebN1jhlfKiAUJRJwOeD11+Hp582PPkkNDU5bZGzHLfLlc4e1u8gOT6WXE8CFfXR54E4\nantdSrJSQo6bnZlMU2cfrd19U2GWoijKtOXWWyEuDtLTweu1Xp2dg5/T0631t93mtKXTHxUQijIJ\nfPCDsGYNXH21cOONcOCA0xY5i38GfbiAAJiTlczRKJxhr2joJC5GKEgLXSbTf86OR+E5UhRFORXu\nvdcSCHfeCcnJVrWl66+33pOTrWpMcXHwqU85ben0RwWEokwwNTXwu98NXeavBBGthBYQKQOz8dHE\nsYZOijOSx+wwPUsFhKIoSliUlsLjj0N7O9x/P6xaBRs3wurV8MADVg7E449rCdeJQAWEokwww5Oz\n3AtrSEj2OmNMhHC8sRN3QizpyXEj1s3JTKamtYeu3n4HLHOOioYO5mSFTqAGBsaU10WfyFIURTlV\nrroKysqguxs8HnC5rJyHri5r+VVXOW3hzEAFhKJMME8/PVhs+q5728m6cSsmM3qbpYHlgZiVmTyk\nhKufOXZidTQlChtjONrQOWb+A4AnMY6i9CT2VbdNgWWKoijTn9JSWL8eWlqgv996X79ePQ8TiQoI\nRZlAvF7YEOCBuO0f4gHYcbzZIYsig+ONncwepdrQHDtEJ5rCmBo7emnv8YblgQBYUpDK3pOtk2yV\noiiKooSHCghFmUD27oW2VmuWPa/Ax9rV8czKTGJHZfQKCGMMxxo7g+Y/wGAVoqMN0eOBqLB/azge\nCICyAg+H69rp7ouuMC9FURQlMlEBoSgTyJ49g59XvUsQgZWzMth+LHoFRF1bDz1e36gCIi05jrSk\nOI42Ro8HoryuHeCUPBA+Awdr2ifTLEVRFEUJCxUQijKBBAqIM86wPBEritM40dJNbWu3Q1Y5y7GB\nhmmjPyyXZCVHlQfinaoWUuJjwvZALC5IBRgRxtTc2cuz71Tj85lgmymKoijKpKACQlEmkD17Bh/k\nysqs9zMK0wCiNgk2VAlXP7POAPf5AAAgAElEQVSzUqJKQOyqauGMwjRcrpFJ5cGYk5mMJyGWbUcH\nOxJuO9rIJV/fzMd+uY3Hth2fLFMVRVEUZQQqIBRlAtm1e6SAmJ/rBgbDVqKNY42diEBRRvAkarA8\nEFXNXfT1+6bQMmfw9vvYc7KVZcVpYW/jcgmXLMnl2T3V9PX76PX6+PTjO0mOj2FZURpfe/YAbdqp\nWlEURZkipqWAEJFNItItIu32a7/TNilKXx8cOjQ4o7x4sfWe7Y4nNTE2qgVEQWoiCbExo46ZnZlM\nv89Q1dQ1hZZNLq3dfdz0/S3c+fM32V01WMb3UF073X0+lhWFLyAArlleSHNnHy8fquf7m8o5XNfB\nQ9cv5f9dW0Z9ew8b99ZM9E9QFEVRlKBMSwFh83FjjNt+LXLaGEU5dAj6vZaAKCz24fFYy0WEeTlu\nDkdpI7Djdg+IUJTYvSAqZlAp19+/eZxtR5vYdqyJ/+/Xbw1UUNpZaYmJpacoIC5cmI0nMZYHn3qH\nbz13gOtXFrJucS5nzkonKS5mYL+KoiiKMtlMZwGhKBHF3r2Dn88oGxrbXprjjmoPRKj8BxisRlRR\nPzMERL/P8H+vHmXVnAy+96F3cbShk29tPAjAn3ecIC81gbnZ4SVQ+0mIjeEb/7ASAZYVpfHf710G\nQGyMizMKU9mlAkJRFEWZIqazgPhvEakXkVdE5OLhK0XkLhHZKiJb6+rqHDBPiTbKywc/L1o4TEDk\nplDT2hN1cerdff3UtPaMKSBy3AmkJcVxoHZmiKy3jjVxrLGT286dw3ml2fzDqmJ+9NJh/rS9ipcO\n1vOhc+YQE2YCdSCXleXxwn0X8+Q9a0mOjx1YvrQojXdOtOKdoTkkIrLADlv9ldO2KIqiKNNXQNwP\nzAOKgB8CfxaRIQ3KjTE/NMasMsasysnJccLGqMAYoyUkbQ4dGvxcWjp0XWmOlUgdbWFMlU12BaYx\n+h2ICIvyPewbpdvy/uo21j9/kJbO6SHA3rFzHs6dlwXAZ9+zhIzkeD752+3Ex7j4wNmzT3vfIjKi\netPy4jS6+vopn7l/X98F3nTaCEVRFMViWgoIY8zrxpg2Y0yPMeYXwCvAe5y2Kxr53qZylv/n3/je\npkMYE91Corx88PePJiCiLYzpUK31QBtOv4Ml+R4O1LSPEKQvHazjyv99kYf/doCfvHx4UuycaPae\nbCMzJZ4cTwIA6cnx/O5ja/j8NWU8ctu7BpZPFMvtik47Z2DHcxF5P9AMPOe0LYqiTA3l5XDPPVBc\nDE88Yb3fc89QT7/iLNNSQATBAKceD6CMi36f4ZevHsXr8/HVZ/az92R09jnwczDAAzF//tB1c7KS\niXXJjBQQuypbRg3NOlDThggsyHOPuZ9F+am093ipah5aiemRzeXkpyaydn4Wv33z+LQo9bqvupXF\n+R5EBi9LpTlu7jx/Lpcszpvw45VkpRDjkhnXS0NEUoEvAvc6bYuiKFPDhg2wfDn8+Mewbh3ceCNc\nfLH1fflya73iPNNOQIhIuohcISKJIhIrIh8CLgSeddq2aGNLeT3Vrd3cf6VVr/TFg9Gba9LbC5V2\nLy8Rw9y5Q9fHxbiYnZVMee3MCjHZXdXCtetf5qKvbWLLofoR6/dXtzE7M3lIvP5oLMq3ylYFNtzb\nV93KK4ca+MdzS7hj7Vxq23p4bm/txP2ASaDfZ9hf08YSu3v0VBAb4yI/NXEgZGwG8RDwE2NMyE55\nmvOmKDOD8nK4+Wbo7LRKo99xh7X8jjus752d1nr1RDjPtBMQQBzwJaAOqAc+AdxgjNFeEFPMU9tP\nkJoYywfOns3ifA+b90fvjfvoUfD5rNnmvAJDYuLIMTOxEtNPXz5CSnwMyfEx/PeGfSPC2PbXtLEw\nzxPWvgYEREAexG9eP0Z8rIsPnD2Lixflkhjn4s2Kxon7AZNARUMH3X0+FueH97sniqKMpBHem+mM\niKwELgW+OdZYzXlTlJlBby90dIAx1uu886zla9cOLuvosMSE4izTTkAYY+qMMauNMR5jTLoxZo0x\n5u9O2xWN7Khs5uy5mSTGxXDRohy2Hm2kvcfrtFmOEDgbsnB+8Gi6eTkpVDR0zJhKOXVtPfx55wlu\nWTWLj104j11VLWw/PhiD3+Pt50h9B4vCFBDuhFgW53t4pdzyZPR6fTy14wSXl+WRnhxPjEtYmOdh\nf3Vkh8r57VucP3UeCIDi9KQZ1YgPuBgoAY6JSDVwH3CTiLzlpFGKokwe991nCQQ/CQlD38Faf68G\nNTrOtBMQSmTQbVd8KbPDNNaWZtPXb9hxfOYlcYZDoICYP4qAKM1x09dvqAzxkHesoZPjjZ3TIiH9\nzYpG+voNN5xZxHvfVYwnIZZfvnp0YP3hug76fYaFpzATf1lZHm8caaSpo5cX9tfS1NnHTWcVD6xf\nlOcZEuIUiRxvtMKISrJDV56aaIozkqhu7Z4WOSJh8kOgFFhpvx4B/gpc4aRRiqJMHhs2wDXXDBUR\ngXR0wNVXwzPPTK1dykhUQCinxYGaNvp9hrJCS0D4470j/eHudBnref7gwcHPwxOo/YxViWlXZQsX\nPfwCF3z1BX6xpeI0rJxa9p5sxSWwON9DSkIs16woZMPuajpsL5S/ItCSUxAQl5fl4zPw9z01fPeF\nQ+SnJnLB/OyB9YvyPdS399DQ3jOxP2YCOdHchScxFk9i3JQetygjCZ+B6pbuKT3uZGGM6TTGVPtf\nQDvQbYyJ3lhJRZnhuN2waRO8733QNWyuravLWr55szVOcRYVEMppseeEFadeVmCVj8zxJJCVEs+B\nGSggvvlNSE0zvOca3xChEMjBg4MKY+HC4GNKc6xSpqMJiP97tYKkuBjmZafwl50nx2PylLD3ZCvz\nctwkxsUAcOOZRXT19fO3PdUAbNxbS2FaIvNzw7/SLy1KpSg9iS889Q47K1v49/csJjZm8DLlz5PY\nXxO5f2dVzd0UpSdN+XGLMyyPRygP13TGGPOgMeZWp+1QnEXLe85sbr0V4uIgPR28XuvV2Tn4OT3d\nWn/bbU5bqqiAUE6LPSdb8STEUpwx+KC0KN/Dvgh+sDsdGhvhgX83tLcJG/7q4ry1PmpqRo7bu39s\nAZGeHE+2Oz5oJaaWzj7+vPME168s4toVhWw71kR9BM+yg9XroCyg0tCqORkUZyTx2zeO093Xz0sH\n67i0LG9IKdOxEBF+cNtZrCrJ4OplBVy3onDI+gEBEcFC9URzF4UOCAi/aJlJidSKEsh4y3uq+Ih8\n7r3XEgh33gnJybBzJ1x/vfWenGxVY4qLg099ymlLFRUQymmx50Qriws8QzriLszzcLCmbUZ1pn70\nUejtGfyN9XUufvWroWN6e+FYxeCY0UKYAOaNUonp2T3VdPf5+MDZs7isLA9j4PkILlfa0tlHVXPX\nkFKlLpdw5/lzef1II//+x1109/m4rOzUex4sLUrjl3eew3c/9K4R4iPHnUB6chyHaiO3mtWJli4K\n04OU4ZpkCuxjzsBSrooy7vKe2ltgelBaCo8/Du3tcP/9sGoVbNwIq1fDAw9YORCPPz6yWasy9aiA\nUE6L8rp2FgyrrrM430Nnb/+MCaEwBh754ciE1N/8dqhAOnIE+vutB92iYh9JISafRyvl+uKBOnI9\nCSwrSuOMwlRyPAm8drhhfD9gEtlXbYWwLSkY+jdw65o5LMxz88TbVSzO93DO3KwJPa6IUJyRxIkI\nnWXv6PHS3NnniAciITaGbHcCNa0zIwdCUQIZT3lP7S0wvbjqKigrg+5u8HjA5bJyHrq6rOVXXeW0\nhQqogFBOg6aOXpo6+5iXnTJk+cKBRmCtwTYboMfbz0d/8SY/2Fwe0dWGjh+HPbtH/hfZtlWG3GgC\n8yIWLQodrlOak0JTZx+NHb0Dy/p9hpcO1nPBghxEBBFhUZ6HQxHcM6K8zgrDGi4i42JcPHLrWXz7\nA2fy50+cT3zsxF9iCtKSONEcmQ/JJ1ssYeNEDgRYuUh1bb1jD1SUacZ4yntqb4HpR2kprF8PLS3Q\n32+9r1+vnodIQgWEcsocabCu4nOHCQh/sqz/4XI0/rT9BBv31vLfG/bx7ecOTY6RE8DOnYOfz7/A\ncPXVg2LnyScH1x04MPh50cKxBMTISkw7K5tp6erjokWDDbDm57opr22PWIFV1dxJrEvITx0ZqjMv\nx811KwqJi5mcy0tReuR6IKpsYeOEBwJsARHhuTOKcjqMp7yn9hZQlIlHBYQCWKEXH/jha2GVDz1S\nF1xApCbGke1O4HCImXOfz/CDzeWUFaRyztxMNuyO3GpDu3YNfl6xXLjhhkFx8Nxzgw/2gQJitARq\nP34BEXiOXjxQjwhDypWW5qTQ0dtPdYSGo1Q1dZGflkiMK/wE6YmiMD2Rth4vrd2RN13oFzaOCQh3\nAvVtKiCUmcd4yntqbwFFmXhUQIRJc2cvWw7VO23GpPGbN47x6uEGvvDUO/z69WMhxx6p7yDWJczK\nHNkoqzQnhcP1o3sgdlW1UF7XwR3nz+XChTnsq26L2Jr+gQJi2TK45JLB75tfHHR3v/X2oJhYvDj0\nPosykoiPdXGgZlBAbD5Qy/KiNDJS4geWlfq9OUEqNkUClU1djoXp+B/OT0ZgGNPJ5i5EIM+TMPbg\nScAKYeqJWM+Vopwu4ynvqb0FFGXiUQERBrurWrj8my/ywR+/zrajjU6bM+H09fv46ctHWF2SwRmF\nqfx+6/GQ4w/XtzM7MzloiMq8HHdID8QbR6zzd+GCbNbMsxJsXz8Smed0+47BBOply2DePJg121rW\n2SG88YYVW7t9++A2q1aF3meMS3jX7HRescVoS2cf2483c9HCnCHj/OFgh2ojs1xpVXPXQN+BqaYg\nzRIQkRjGVNfeS1ZK/JDeFVNJjieB3n4frV1eR46vKGNxuqVUx1PeU3sLKMrEowIiDH7w4mF6+314\nEmP5xZajYW/n7ffxT/+3le88N0r3sQhh29EmTrR0c8fauVxels+OyuaQXoHDdR0jwpf8+JOEmzqC\nJ3K+UdHInKxkclMTWV6cRnJ8TERWG+rthQMHBsNzli613i+7dPC/zHPPWV6Kvl5r3Kw5PrKzGZOL\nF+Wyr7qNky1dvFJej8/AhcMERI47AU9i7Jj5JE7Q6/VR09pNUYYzHohI7ndQ19ZDttsZ7wNAttvy\nYtW1R553RlHGU0p1POU9tbeAokw8UScgTtW17/MZXj5YxyWLc7nlrFk8veskdWHGGP/ytaP8fU8N\n39h4gDcrInOWHSwPC8DquZlcsjgXY2DT/rqgY30+Q0XD6AJint1t+XD9SC+Ez2fYWtHI6pJMwKrY\nc+bsdHYcb56InzGh7N8P/V5LGBTPNqTa7Q4uvXRwzFN/Nrz55uD3c88JLx9g3aJcADbvr+P3W4+T\nkRzHylnpQ8aICKU5bo6ECAdziuqWbnwGih1MFI51SUR6IOrbe8hxKHwJGDh2reZBKBHGRJRSPd3y\nntpbQFEmnqgSEM2dvax7eBMPP7s/bCGx+0QLTZ19XLgghxvPLMLrM7waxox5j7efb/ztAGvnZ1GY\nlsTDz+4fr/mTxq6qFgrSEsl2Jwz0INh0ILiAqG7tprvPx9ycUQRE9uiVmA7Xt9PU2cfZtoAAK6n4\ncF1HxMVsByZGLztj8PNVV0FMrGXrtq3CH/4wuO7ss8MTEAvz3BSmJfK/zx1k0/467r6oNGjIS1GE\n9juobLYalTnlgYhxCXmpiZxsibxZdqc9ELm2gKhv11KuSmQxUaVUT7e853h7C2gXa0UZSlQJiJ++\nfISKhk7Wv3CI/3s1vFCklw5asernL8hmcYGHhFgXO8OYMd9V2UJbj5d/PLeE9yzL5+3jzfR4+8dl\n/2Sxq6qFpUVpgNVN+Oy5mbx1tCnoWP+M+GgeiOKMJOJjXEE7Bb91zDpv75qTMbBsXnYKbT3eiCs9\nWVEx+Lm0dFAYpKfDuwOSqTduHPy8enV4+xYRvnbLCvr6DUXpSXz4vJKg44rSk6hq7oo4cVXV5Gyv\nA4CCtMSBnguRgjHGeQ+E2yqrG66XVFGmikgopXq64kO7WCvKSKJGQLR19/GzVyq44ow8lhWl8eT2\nqrC2e7OikUV5HrLdCcTFuCgrTGVnZUsY21kP4KvmZHDWnAx6vT7eORG6wZoTtHX3cbiug2W2gABY\nWZxOVXNX0IcQf4UlfznS4cTGuCjNdXOgZmTy787KZjwJsUMa0M0bKGsaWaE6gQJizpyh6266aaSn\nISPTx9lnh7//tfOz2fTpi/nzJ84nMS4m6JjCtER6vL4hTeciAX8Tt4L0kT0gporc1ISIC9Np7/HS\n4/UN5CE4QWpSLPExLhUQSsQxXUupahdrRQlO1AiIN4400tbj5cPnlXDxohx2HG8Oq478geo2lhQM\ndttdUZzO7hMt9PtCzwpvrWhkXk4KWe6EgRn30Wb1nWSPLWoCBcQKOx5/Z+VIT8vhunaS42MGQiWC\nsSjPzYHqYALC8nS4AnoHDORMRLCAKCkZuu697wVP6tB//8/9h4vEU3yedifEkpky+sNmQbq/2lBk\nherUtHWTmRJPQmxw4TMV5HoSqWuNrIdk/0O7kx4IERko5aookcR0LaWqXawVJThRIyC2H28mxiWs\nnJXO2vnZ+Ay8Vh46l6Glq48TLd0szB8UEMuL0+js7Q8aouPH5zNsPdo0EOuf60lkdmYyWysiT0Ac\nskuuBv7GpUWpuISgyc1H6q0EapHR4/0X5ns40dI9RKD1ePvZe7KV5bPShowtTEsiIdYVsvSrExw5\nMigQhguI7Gz4y5+FxGSrpOusWYZ//ueJtyFSqw3VtnaHFJBTQY4ngbYeL129kRMW6M87cDIHwjp+\nfMSFBCrKdC2lGgmhV9MVzRuZ2USNgHj7WDOL8jwkx8dy5ux0kuJieHmMxnD+MJzFwwQEWHkDo3Gk\noYOWrr4hsf7vmp3O9gisNnSsoZP4WBcFqYPT58nxsSzM87A9SKiWX0CEYlGedb4OBoQx7TvZRl+/\nYUXx0GpDLpcwNzt087mpxpjQHgiACy+E7W+5+J//gRdeEJImIR1goGFahMX617b1kJfqXPgSMHD8\n2rbI8c74Z/2dFhCZKfE0dqiAUCKL6VpKdbqGXjmN5o3MfKJGQOw43syZs62H14TYGM4M44F+vx2G\nsyg/dWBZSVYK8TGuoDH+fvadtNaVFQxutyDPQ3VrN+09kdXgqaKhg1kZSUPCioCB8qqBCbw93n6O\nN3YOyWEIxkJbQOyvHvQq+M+1X4AFMi8nJaI8EE1N0NFhnY+kZENWVvBxixZZJQEnq/RfRnIciXGu\niKvEVNPaTV6qsw/JuRFYrrS+3fkQJoAsdwKNWoVJiTCmaynV6Rp65SSaNxIdRIWA6Onz0dbj5czZ\ngx6BsoJU9lW34e33jbrd/uo2PAmxFKYNzrbGxriYl5MSUkDsr27FJYPdhGHwc3mI0CcnONrQyZys\nkYJgRXE6LV19VDR0Diw7WNOOzwwVVMEoSk8iJT6GvScHk8ZfO9xAUXpS0Mo9szKTqWruwjdGXslU\nEeh9mDXbECJaa1IREQrTkyIqB6LfZ6hr6yHX46wHItcWMDWtkXNu6tt7cAlkJDuXRA2QlRJPfUdv\nxFXvUpTxllJ1gukaeuUkmjcSHUSFgOjqs2b9A2e/ywpT6fX6Qjbq2l/TxoI894h4/0X5Hg7WjC4E\n9lW3UZKdMqS6jr9qUXkYM+3lde3840/f4J9/tW1SkyGNMRxr7GROVvKIdf5E6sA8CH/DuaVFoQWE\nyyW8a07GQIdpn8/w+pFG1szLCpo7UZyRTF+/iZjZ5CElXOc5pB5sitKTqIwgD0RDew8+QwR4IOwQ\npghKpK5r6yHLnUCMy9m/mSx3PL1eHx0RlB+iKH5Ot5SqU0zX0Csn0byR6CAqBES310dcjAyJ3V9i\nhxftOTl6adXDde0syPWMWL4wz0NVcxdto1RxOlDTNiRvAmBOVjKxLgmZfO3n569U8Gp5PRt2V/PH\ntyrHHH+61LX30Nnbz5zMkQJiQa6bpLiYIWFeu0+04EmMZXaQ8cM5f342B2vbqWnt5mBtO40dvayZ\nlxl0bLHdkKyyqTPo+qkmUEDMLXH2YbAgLZHqCMqB8Iu8XIdzIDKS44iLkYgRnWB5IJzOfwDITLFs\naNBEakUZN9M19MpJNG8kOogKAdHT52NudgpxAd1+S3PcxMUIe08GD0Vq6eyjvr13oMxoIAvscKSD\nQcRAZ6+Xo42dLMobOksfF+NiTlbymB6Ivn4ff911kivOyGdZURpP764e8/cFsruqhT9trwqrRO0x\nOzxpTpCchtgYF8uK0tgRUMp1V1UrSwvTQlZg8rN2fjYAW8rrecVOVl8zL3gywawBAREZD8rHjg1+\nHt4DYqrJT0uitq2HvhChdlOJP2TI6SRqESHHnRBxSdRO9oDwk2Xb0BBh/UMUZboyHUOvnETzRqKD\nqBAQ3X39IzwJ8bEu5ud6hsTpB1Jebz3oB2uYtih/ZJUhPwdr2jFmcEwgpTnuMT0QLx2so7GjlxtW\nFnHVsnx2HG8Oe2beGMO//OZtPvnb7dyw/pUxe1Uc9QuIUTwK75qTwe6qFlq7++jr97H3ZOuY4Ut+\nygpSyUiO4887TvKTl4+wrCiNWaMcpyjdWh4pHojjxwc/z5rlnB1geSCMiZzOwjV2yJDTZVwBclIT\nI+a8gFXG1ekEarByIAAaNJFaUSaM6RZ65SSaNxIdnLKAEJEsCWcKehIRkUwReUJEOkTkqIh8MNT4\n3n7fkIRmP0sKPKOGMPkbmwXzQMzKSCYxzsWBIHkQg5WbRgqI+blujjZ0hpxNfvFAPUlxMVy4MIcr\nz8gH4IX9daOOD2Tb0SYO13dwwYJsDtd3sG2MxnVHGzpwiZWDEIzLynLp6ze8sK+WXVUt9Hp9LC0a\nWUUpGC6X8I/nlvD8vlqqmru4/8rFo45Nio8h250QMR6I48cHhZfTAiLfTuA/2RIZM+1+D0QkPCjn\nehIiJgfCGENdew85ERDClGXboKVcFSVyiKaeCJo3Eh2EJSBEJE5E/ktEmoEaYK69/L9F5O7JNHAU\nvgv0AnnAh4Dvi8gZoTbwlxYNpKwglbq2noHyi4GU17UTFyNBZ81dLmF+rjtoJaZ91W0kxrmC5gmU\n5rjx+qzE5dHYUdnMsqI04mNdzM1OITUxdqBb9Fg8trWS5PgYvv4PK4iPdbFh98mQ4482dlKYnkR8\nbPA/gzNnZZCXmsCGXdX8/s3jJMXFsG5xbli2APzrpQu497KFfGRtCecvyA45tjgjKWIExNGAECan\nBUSBLSCqI0RA1NphOoHhgE6R64mcEKbWbi+9Xl9ECCu/B6JePRCKEhFEW08EzRuJDsJ9Cvg8cBNw\nJxD4tL0N+MhEGxUKEUmxbfm8MabdGPMy8BQQ0hm2IG+kB8LfpyFYGNPhunZmZyaP+qC0MM8TVEAc\nqGljYZ4naCUWvxdktDCmvn4f75xoHagWJSIsKUgdNcwqEGMMz+2r5bKyPHI9iVy0MIdndleHLOVo\nlXAdPSHa5RKuOCOfF/bX8qftJ7huRSGpiXFj2uJHRPjEuxfwhWtDajvALyCcD2Hq7YW6WuuziKGw\n0Fl7ClIjq5mc1YXa2fwHP7meRJo6++j1Op8f4p+EiIQk6sS4GFLiY2jUHAhFcZxo7YmgeSMzn3AF\nxIeAjxlj/gAE3q13AYsm3KrQLAT6jTEHApbtAIY8pYrIXSKyVUS2xomhJEivgyUhBER5XQfzguQ/\nDBiR56GmtYeWrqHJyvuq2wY6MQ/HHw41WiL1/uo2er2+gRKqfhv3V7eNmc9Q02p5Us60t71kcS4n\nW7qH9HEYztGGDmZnhm4Kd9eF81henEZvv4/bzp28jOLiDKsXxFi/c7KpqgJjLPGXk2eIC18vTQqp\nSbEkxcVEjAeipq17oAeD0/jtqIuAakOR0oXaT6Y7XqswKZNGNIXjjJdo7omgeSMzm3AFRCFQEWR5\nDBA7YdaEhxtoGbasBRjy1G6M+aExZpUxZtXiwvSgYToZKfHkpyaOqMTU6/VRUd8xUG0pGAttj0Zg\nInVDu/UQHyz/AcCTGEdeasKoHgh/xaMVxYMCoqwwla6+fo42jN6vAmCX3aNhme298O9jZ2Xwbtut\n3X00dfZREsIDAdaD/WN3n8f2/3dZ2PkPp0NxRpLdC8LZB+XABOrZs50t4QqWFyc/LZHqCGmYVtPa\nQ17EeCDsbtQRcG4ipQu1n6yUBK3CpEwK0RaOM160J4IyUwlXQOwBLgiy/Bbg7YkzJyzageGlgFKB\n0VtDh2BJgWdEjsHh+na8PjOqEIDBnIr9AQLCn0C9OESn5vm5bsrrgouBXZUtpCfHMStzsFtzWRj9\nKsASEC4Z9KoszHOTGOdix/HhWstioITrGALCj+cUQpdOh+IIKeUaKCBKIkBAAOSnJkaEB8Lb76Oh\nvcfxJnJ+BprJRUAlpvoBD4TzZVzBskOrMCkTTbSG44wH7YmgzFTCFRBfBL4tIvfb27xXRH4EfBZ4\naLKMG4UDQKyILAhYtgJ453R2tqQglfK6dnq8g11bwxECRelJpMTHcKB6UEDsPmE9rC8uGF14lOa4\nOVzbHjQ3Yc/JVsoKUof0WZif6ybGJewbpV/FwLGrWijNcZMcbzmEYmNcnFGYNqoHosL2aMwJEtrl\nBP5KUE7nQURSCVc/BWmJEVGFqaGjF59xvomcH38IUyQIiLr2HmJcQkZyZAiIzJR4zYFQJpxoDsc5\nXbQngjJTCUtAGGP+hJUHcR1W2NKXgWXADcaYv02eeUFt6QD+CHxRRFJEZC1wPfDL09lfWWEqXp/h\nYEBJ1n3VbcTFSNASrn5EhOXF6WwNKJX6xpEm5manhIyDnp/rpq3HO+Khx9vvY39124DHwU9iXAyz\nM8duQLe7qoVlw0KMlhensftEC94gZWP9PSDC6So9FQx4IBpDeyDq23v40/YqfJOUKxGJAiI/LZGa\n1u5J+83h4i/hGgk9IOawEewAACAASURBVMCqNiQCdZEQwtTWS1ZKPK4gxROcIMudQENHT8giCpGO\niCSIyE/sUt1tIvK2iGjqpYNoOM6pM917Imi+izIaYddiNMY8bYxZa4xJNMYkGGPWGGOcina8B0gC\naoHfAP9sjDltDwQMTaTeX91md6oOfXrOmZfJnpOttHT14fMZth1tZHVJRsht/I3pyoflQVQ0dNDj\n9Q3YM3SblIG+FMFo6uiltq1nhOdjRXE63X2+oB2zK+o7yPEkkJIw1SkswUmMG7sXxMmWLm7+/hY+\n+dvt/HVX6BK1p8uxY5HTA8JPQVoiXp+h3uG6/v4mck53ofYTG+MiKyUhYjwQkZJADZa46us3tPV4\nnTZlPMQCx4GLgDSsaoC/F5ESB22KajQc59SZzj0RNN9FCYXzxdxPA2NMozHmBmNMijFmtjHm16e7\nr5KsFBLjXEMSqfdXt4XMf/BzztwsjIGtFY2U17XT1NnHqpLMkNv4BcShYR6FPfbxgwsIN0fqO0at\nUOTf14Jh1Z/85WCDhTEdru9gXnZkhC/5Kc5IorJ59BCmH2w+zMmWbmZlJvGtjQcmpWJT+eHBfc6d\nO+G7Py3y0yzvjNN5EP4E90gREAB5qZEhIOrbeyImgRogyz39u1EbYzqMMQ8aYyqMMT5jzF+AI8BZ\nTtsWrWg4zqkzXXsiaL6LMhbhNpJrEpHG0V6TbeRkEuMSFuUP9lpoaO+hqrkrZP6DnzNnpxMf4+L1\nI428dsQ6DWePISDyUhNwJ8SO8EDsOdFKXIwE7Zg9LyeF3n7fqPkB/vCr4VWjSrJS8CTGsqNyZCJ1\neV07pSGqTDnBWM3kXjlUzznzsrj/ysWU13XwyqH6U9r/fz29l1t//PqojfmMgYqKwRCUkpJT2v2k\nURAh3ahrWnsQiZxEYYicZnL1bZHlgchMsWyZSaVcRSQPq4z3CG9zYNnuurq6qTcuSpju4ThOMd6e\nCE6EEWm+izIW4Xog7gM+HfD6LPAY0IeVYD2tKSvwsOdkK8YYXjpoPZSunZ815naJcTGcPTeTP2yr\n5JFN5SzMc49Z1UhEKM1JGeGB2HuyldIcd9Bys36vxWhhTAdr20iOj6EwLWnIcpdLWF48MpG6saOX\n5s6+CPRAJHNilF4QtW3dHKxtZ21pFhctzEEE3j4WPEE8GCeau/jJy0d4pbyeW3/yetDmYw0N0NVp\nCYjkFENmaC04ZeRHSDfq2tZuslISiI2ALtR+cj2J1LY6+5BsjKG+vTeyPBB2N+qZUspVROKAR4Ff\nGGP2DV8fWLY7Jydn6g2MEqZzOI7TnG5PBKfCiDTfRRmLcJOofzLs9Ygx5mPA54BVk2vi5LO0KI2W\nrj72nmxj84E6MlPiWVoYXs+DL1xbRkevl6rmLr54/dIhFZRGozTHTXnt4P9MYwzbjzcP6f8QiL+h\n3WiJ1Idq25mf6w6awLmsKJ19J9vo7husMnXY3k9piEZ5TuDvBRGs58Gr5Q0AnFeajScxjvk57oG+\nGeHwf68exRjDg9eeQWNHL6+Uj/ReVFQMfp4zxxDGP+WUkJkcT3yMKwI8EN0Rk0DtJzc1gfr2Hkcb\nELZ2eent90WUZ2YmhDD5EREXVpGMXuDjDpsT1UzXcJzpipNhRJrvoozFeKcSn8OqgDStec/SAhJi\nXfzq9aO8eKCOCxdkh11NZUGeh+/fehZfvP4M1swb22sBUJrrprq1m3Y7wfFIfQctXX2cOTu4gMhM\niScjOW7U/hF+ARGMFcVpeH2GfQHlZssjVED4q14dCfI7XzlUT1pSHGWFVmjZylnpbD/eHHaVmSff\nruLdS/J4/9mz8CTG8pcdI5OwAwVE6bwIUQ9YnqS8tASqW5ztkXGypZvC9MjJfwArhMlnoMHBBPO6\ndkvYRZIHItP2QDQ6nHg/XsSakfkJkAfcZIzRgAmHGW84jhI+ExFGdLrhT5rvoozFeAXELUDDRBji\nJBkp8Vy7opBfv36Mho5eLi3LO6Xt1y3K5R/PLQl7vP/B3d/F2h+Kc+bs0Ss4zctxB/VAtHX3cbKl\ne1QBsXzWyI7Uh+s6iI91UZSRFHQbp5gfwtOypbyBNfMyibGF3YpZ6TR29IbVeK6mtZvq1m7OnZdF\nQmwMl5fl87c91fQNK28bKCDmzo0cAQFQkJrkuAfiRHMXhemR9TeT428m52AYU12bNcufE0E5EAmx\nMXgSYqmf/h6I7wNLgGuNMc4qaGWA0w3HUU6N8YYRjSf8SfNdlLEIN4n6bRF5K+D1toicxOoH8T+T\na+LUcNeF81hSkMqXbljK1csKJvVYfk/D63bi9dvHm3AnxI4qAmD0Uq6Hav0J1MGrRhWmJZLtjh/S\nkfpATRtzs1IGHsYjhRxPAp6E2BEC4lhDJ5VNXaydnz2wbKUtjLYfHzuMaaedRL5ilhWW9u4lubR1\ne9ldNTS5PFBAREoCtZ/8tMSgoV1TRXuPl9ZuLwVpkSUgBpvJOXdu6u1E5ewI8kCAFcY0nZvJicgc\n4GPASqBaRNrt14ccNk1RpoTxhBGNN/xJ812UsQi3CcBfhn33AXXAC6fbfyHSWJjnYcMnL5iSY+Wl\nJrI438Pm/XXcfVEpWyuaWDErLeQDfWmOm99vraSls4+05LiB5Qdrg1dg8uNveOf3QPh8hreONXPl\nGfkT+IsmBhFhXu5IT8sWO1/hvNLBELEFeW5cQtAeF8PZWdlMjEsoK7AExGq7UtYbRxqHeH2OHDGA\n9W8QaQKiIC2RZ97pxhgTVp7NRHOy2Zr8jcQQJnDaA2ELiAjyQIAVxuRkaNd4McYcxf8fUlGikMAw\nosceg6SA+ZvAMKLUIEUj/eFPfnrsS4E//MnPvhElCSyG57t84xvWdqtXw7/9G1x4oea7RDvhJlF/\nftjrC8aY9TNFPDjBRQtz2Hq0kdcON7Cvuo3/v707D4+qPBs//r2z74RsbCEBwhogoIRFUETRIkWK\ntqBVtKi8okV/pSotWu0rVtS3rdraYtvXosjrXlFcimBFiQqIlbLJLiGEJSwJEMhKtuf3x5kJWWYm\nE0gyk5n7c13nSuacMzP3OTOZnHue57mfqwa47jZVO5C6oP4F897jxYQEBdDdxYzSGckd2JtfTPHZ\nKvYcL+J0WSXDe3pJiaEG0hIj6w0wB1ibfYKk6NB6YzZCgwJJ7hhROyDclS2HTtMnKYrwkEDAauno\nlRjJv3PqVyDetfvcp6q3JRCdO4RRUVXjsW+UD9sSiG5e14XJ3gLhuQvlguKzBAUIseHBTe/chuKj\nQn1iELVS/upCuhG1RBUlHe+iXPGeeox+5vK+iVRWG+5/azMRIYH8aFiyy/3TbAOMG3Zj2nu8mLTE\nKJetF0OSYzEGth0+zTf7TwFNz1fhKWmJ9QeYG2P4KruAMb0TGn3z3jPB9Qzd9vt/e6hxhauRPeP4\n9/6TtdV7Skthf471+CKG/v1b6ohaRootQdx/wvFcIMaYepW2Wpp9/EUXL0sgQoMCiY0I9mgXpvyi\ns8RHhbhdeKGtxEeG+EwZV6X80YV0I2qpKko63kU54zSBaGryOF+ZSM5TRvSM49qMLuSdLudHFycT\nE+b628vucREEBUij7j3fHS9y2n3Jbkj3WAIEPtlxjG9yTtIpJpTucd51IWhXO1O3rWvSnmPFFBRX\ncEla4wpXvRIjySkoocZFCc+C4gpOlVY2mll8ZM94isqr2HXUmlRuxw6oqbEuAHulGSJcT+fR5nra\n5uzYX+D4v8ETy3eSuWBVbbnblpZXWEaAQCcv6+cPtsnkPNiFydtmobZLjA7lhIdL3Cqlzt+FlM3V\nKkqqtbkaAzG3zaLwQ0GBASy8+WLmjC9y2f3ILjgwgNT4+l12SiuqOHSqjBuGdXd537jIEK67qBuv\nrLfmQrhuaDeP9KN3h31w9Nf7TjC0e2ztbNOjHSYQUZRVVnP0TLnT6kD282UvEWs3oue5cRADu3bg\n22/rxDDE+85N97gIAgOEHAcJxH9yT/Hi2hxCAgO4/eV/s2belS3eHz+vsJxOMWFeNYmcXVJ0mIe7\nMFV43fgHqF/iNinau8auKKXcM3GiNdD544+tbkTFxfW7ETlrCbjlFqvaUt3uTxUVEBKiVZRUy3B6\nNeBg8jinS1sG7Gv6dIomLDjQrX37drJmzLbbe7wYY3BZvcnuvqv6YowhNT6SRyaln3e8ra1zhzD6\nJEWxxpY4rMs+QWp8BMkdGydZaQmOu3XVtc92wd1wzouuseEkdwyvHQexdeu5bRkZ3pdABAcG0L1j\nuMME4k+ffkdSdCgv3z6C8sqa2qSrOT7fk8/7mw87nVfDG0u42iVFh9YOZPaEY2fKvaqEq11SjOdL\n3CqlLtz5dCPSKkqqtXnf14nKqYtSYjl4sqz2YmljrjWeYUh3xxPQ1dU9LoL377mUt++6pF4VJ280\npncC3+w/yZHTZazZm8/YPokO97MPLM8pcD6Qel9+MaFBAQ4H/47oGce/c05ijGHLlnMXzhkZF3gA\nraRnQmSjBOJMeSXrsgu4bmg3RvSMIzYimC+/a14Ccbq0kntf38icNzfzwNtbHO5z2IsTiMQYK4Fw\nd1LBllRRVUN+8Vmvm1MFrGpvYCU4Sin/orOGq9bm7jwQwSLyaxHZYavDXVF3ae0gleViW8nRTQes\nxOGb3FN0iw13+8IuvWsMHW0z1Hqzy/okUF5Zw72vb+JsVQ0zRvdwuF+nmFAiQwKdztANVutEz4RI\nhwNcR/aM40RJBXuOFrNxc3tIIKLIKSipd6G8etdxKqsN3xvYmcAAYXRaPGv3FjTrYnrRmn0UlVcx\ncVBn3t14uFFlq/LKag6eKq0dyO9tOkWHUVFdw6nStp+k+OjpcozBK5OrJC+oUKWU8hytoqRak7st\nEL8B7gSeBwKBh4FFwGlgTuuEphoa1K0DwYHCxgOFGGPYsP8kmT2cz17dXo1OS2Bwtw78J/cUVw/o\n5LSLlojQMzGytpuSI/sKShqNf7C7rE8iAQL/88JpTp+y/hTiE4zXlXC165kYSVllNcfqdElZue0o\nSdGhXGRrhRrTO4Ejp8tdnpO6jDG88e+DXJ3eicd+MJDAAOHt/xyqt4+9q5yzyQo9zV6hKveEe8fc\nkg4VWlWxkr0wgbAP7NYWCKX8l1ZRUq3F3QTiRuAuY8zzQBXwrjFmNvAYcEVrBafqCwsOJL1rBzYe\nOMWhU2UcO3OWTC8tx3ohwkMCeXf2aJ6ZNoTfTBnkct9eCVFO54KoqKrhwMlSeiU4TkC6xoYzfkAn\n3nn13ADTmXcIAV7asa+3rcvWTts4mPLKarJ25/O9gZ1qW1jsrVTb8844fpAGDp0qo6D4LGP7JpIU\nE8a4vom8u/FQvco99opYfTt5Z7mOHgn2BMJxidvWlFdoXZx7YwtEcGAACVEh2gKhlFKqxbl7qdQZ\nsE8aVwzYO91/BExo6aCUc2PS4tmw/yS//3g3YHXD8UXBgQH8aFgynTu4rh7TKzGSw4VlDudAOHCy\nlOoa47QFAuDKLr0o2psAWPM/3H33hcXdmoZ2jyUkMICv9lmlWr/Yk09ZZTXXDOxSu0/PhEgC5NxF\nf1M2HbRmKLe3YEy5qBvHzpxl88FTtft8d7yIoAAhNd47uzAld4xABPZ7oAXi8CmrPmJT71NPSYwO\n47i2QCillGph7iYQBwH7VUo2cLXt9xGA/ndqQ7PG9qJDeDAfbMnj+ou60beTd3YraSu9EqMwxvHF\n47kSrs6/Oc/fea4L2LXXCj17tnyMLSU8JJCLU8+Vtv14+zE6hAczste5JDIsOJCUuAj2Hi9y6zE3\nHygkLDiA/rZ5Mi7vm0hQgPDJjuO1+3x3rJgeCZGEBHln00xYcCBdO4Q7nSOjNeUVlpEYHep2JbW2\n1ikmtF6XN6WUUqoluHtF8AHnkoY/A4+LyHfAEmBxawSmHIuNCGHBdYMZ3qMjj0723nKsbaWXi1Ku\n9nEArlogfvYz4dtv4ac/hZ//vHVibEmj0xLYceQMe48X8/H2o1w1oBPBDeZm6J0UzXfH3G2BOEVG\nt9ja+R3sCcknO47W7vPd8eImJyv0tB4JEU5n6W5Neae9tzoVWAPMPTlLt1JKKd/kMoEQkfEAxphf\nGGMW2H5/C2vcw9+BG40xD7Z6lKqeSRldePvu0cRGeH9FpdbWszaBaHzBvC+/mISo0CZn+R40CP7y\nF7jyylYJsUWN6R2PMTDjpX9TVlnNT8c1HgnXp1MU+0+UUFld4/Kxqqpr2J53hiHdO9Rbf/WATmTn\nl7D7aBHHi8rZf6KEAV1iWvQ4WlqP+EiPdWHyxgHUdkm2Erc6G7VqKDsbZs+G5GRYtsz6OXu2tV4p\npZrSVAvEJyKyT0QeFpGu9pXGmDXGmN8ZY95r5fiUcikyNIjOMWGOWyDynVdgaq8uTunIXWN7cbiw\njJtGdHdYoapPUhSV1abJQcWHC8uoqKppVF1p8pCuhAQG8PrXuSzfegRj4PuDO7focbS0HvGRFJZW\nUlhav6r086v3MulPX/Lcqu9a/DlragyHC8vo4qXjH8Aam1FjtBKTqm/FCqtc9aJFcMUVcP31MG6c\ndTsjw9qulFKuNJVADATeBf4fkCsiy0XkOhHxzg6/yi/1Sowk20H/930FJV47d8H5EhEe+v4AVs8d\nx6OTBzrcx55UNDUOwj4pXc8G5yg+KpRJGV14Z+Nh3vrmIOldYujtpSVc7ewtUXUHj+85VsSzn+zh\n6Oly/rBqD7uPujcuxF0HT5VytqrGrZngPaWHbeC7JypUKe+UnQ1Tp0JpKVRWWjMSg/WzstJaP3Wq\ntkQopVxzmUAYY3YaY+YCyVilXA3wNnBYRH4rIv3aIEalXOqVGMm+/OJ6k6cVllZwsqTCaQnX9q5n\nQmSjsQ91twHkFLi+aLQnED0cVFe6Y0xPKqtr2HW0iOsv6naB0ba+i1OtwfBf55ysXbdg+U6iQoN4\nc9YoAgOE9zYfPq/H/mb/SbJ2H2+0foetVG56V+/t3uXJOTKUd6qosGYhNsZaRo+21o8Zc25dSYmV\nTCillDNuDaI2xlQZY941xlwLpAJ/An4I7BCRL1ozQKWa0ishiqLyKgqKz3Vfya6twORbLRDuiA4L\nJi4yhAMnXV807i8oISo0iISoxmNpBid34KuHxvPmrFFOZwL3JnGRIQzoEsO6bKtC1a6jZ/hiTz6z\nxvaiT6doLuuTwAeb86hp5liAE8VnuePlb7ht8TfMW7q13rYdR84QGCBeXQmta2w4wYHikQHmyjvN\nnWslCHahofV/grX9gQfaNi6lVPvS7LqMxpg84C9YSUQhMKalg1KqOexJQk6dbkw7jljdVbx98G9r\nSYmL4MDJJlogTpTSIyECEXG4PS4yhFG94r22fGtDo9Pi2bD/FOWV1by0Joew4ACmj0wB4PuDunC4\nsKw2sXTXM5/soayimuuGduWtDQfZeODc/Bg78s6QlhjptSVcAQIDhO5xEU0mk8p/rFgB115bP4mo\nq6QEJk2ClSvbNi6lVPvSrCsDEblKRF4H8rBmoX4TyGyNwJw8f5aIlItIsW3Z3VbPrbxXmm2eh7qV\nmHbknSE2ItirB7i2ptT4iCb7ve8vKKGnD3XxuqRXPGeranjmX7t5Z+NhbsjsXlupbFA3q9LUjiPu\nzdANUFldw7KNh/nRxck8cf1g4iJD+POn5wZj7zhyhvR2kKD2iI9kfxPd2ZT/iIqCrCy48UYoK6u/\nrazMWv/559Z+SinlTJMJhIikiMijIpID/AvoCswCuhpj7jHGbGrtIBu41xgTZVt0DIaia2w4IUEB\ntfM+wLmLO2ffrvu61LgI8mxVlhypqKrh0KlSesZHtHFkrefSPglkJHfg71/m0DU2jLkTzn089E6K\nIjhQ2HnE/YHUO4+coayymkv7JBAZGsR/XdaT1bvz2XqokONnyjlyurxdtHBZyWRJvTFCyn/dcgsE\nB0NsLFRVWUtp6bnfY2Ot7bfe6ulIlVLerKl5ID4B9gF3YbU29DXGjDPGvGqM0bqAyisEBgg94yPJ\ntlXgqaquYVc7+Xa4taTER1JjrFKtjhw4WUqNgR4JvjNGJCw4kDdnjeJnV/Zm0U+G15v/IyQogN5J\n0exsRgvEf3Kt7kqZPawB2j+5pAexEcH86dO9vLxuPyJwVXqnlj2IVtAjPpKSiup6Y4SU/3rgAStB\nmDkTIiJg61aYMsX6GRFhVWMKDob77vN0pEopb9ZUC0QZ1mDp7saYh4wxe9sgpqY8JSIFIrJWRMY5\n20lEZonIBhHZkJ+f34bhKU8Y1K0DGw+coqbGkFNQwtmqGq+ujtPaUuNdV9/Zb6/A5EMJBEBESBD3\nf68f/To3Htg8oEvzEogNuafo2iGMLh2sieKiQoOYOaYnq3Ye44Uv9vH9QV1qu895M3uMzTl25bvS\n0mDpUiguhnnzIDMTVq2C4cPhwQetMRBLl1r7KaWUM02Vcf2BMeYDY0x1WwXUhHlAL6Ab8ALwoYg4\n/JgzxrxgjMk0xmQmJia2ZYzKAy7rk8Cp0kq2551h04FCwLvLa7Y2e/lOZwOp7QPOe/lYAuFKepcY\njhed5UTxWbf235h7imE94uqtu3tcGg9c3ZeUuAh+Nr5Pa4TZ4i5OjSUoQPhq3wlPh6K8xMSJkJ4O\n5eUQHQ0BAdaYh7Iya/3EiZ6OUCnl7bymvIptgLRxsqwBMMZ8bYwpMsacNcYsAdYC3/ds5MobjOmd\nAMAX3+XzwZY8UuIi6OfF5TVbW1J0KGHBAU4HUuecKCE2Irh2kLE/6N/ZSih3H2t6HERhaQVHTpeT\nYRt8bRccGMD/G9+Hz+aOc9jK4Y0iQoIY2j2WddnnEoizVdVsPVTIoVM6uNpfpaXBwoVw+jRUV1s/\nFy7UlgellHuCPB2AnTFm3PncDfDPUbKqnsToUAZ0iWHZpsNk5xfzsyv7+O0AarBmrE6Jc16JaX9B\nicMJ5HyZvVvXwZOl0MRFkn3eBF/p4nVJWjzPr97LmfJKjIFpf1vHnmPFJEWH8vkvriA8xHtL0Sql\nlPI+XtMC0RQRiRWRCSISJiJBIjIdGAt87OnYlHeYPjKF7PxijKFdzJ7c2lLiIq2LZQdyCkr8qvsS\nQJcOYQQFSJPzY8C5sSM9fKRK1SVp8dQYWPRlDne/8h9yCkr42ZW9OV50llfX53o6PKWUUu2M17RA\nuCEYWAD0B6qBXcB1xhidC0IBcMuoVEb2jOPQqTKf+eb4QqTGR7B2bwHGmHqtMWUV1Rw5Xe535ygo\nMIBuHcM5cNJxZaq69heUIgLd43wjgRjVM57vpXfiT59+R1CA8PtpGVx/UTKbDhbyv1/sY+alPQkI\n8N8WO6WUUs3TbhIIY0w+MNzTcSjv1qdTNH38eOxDXanxEZRVVpNfdJakmHMT6uWe9M0KTO5IiYvg\ngJPKVHXlniihS0yYV88y3RwBAcKfb76I51dnc3nfRIalWqVpJ2d05cvvtpJzoqRdVJRSSinlHdpN\nFyalVPPYKzHlNuiysy/f/yow2aXERbjVhWn/iRJSfWyMSGhQIPdf3bc2eQC4KCUWoLZymbcRkTgR\nWSYiJSKSKyI3ezompZRSmkAo5bPsF8ANB1LvtU241yvRty6Q3ZESF8Gp0krOlFe63G//iVK/aKFJ\nS4wiOjSIjQdOeToUZ54HKoBOwHTgryIy0LMhKaWU0gRCKR/VLTacAKFRl529x4vpFhtOREi76cHY\nYmrnx3BSnQrgdFklJ0sqfGYAtSsBAcLQlFivbIEQkUjgR8CvjTHFxpg1wAfArZ6NTCmllCYQSvmo\nkKAAkjtGkF3QOIHoneSf/d1T6pZydcKeXPhaFyZnLkrpyO6jZyitqPJ0KA31BaqNMXvqrNsCNGqB\nEJFZIrJBRDbk5+e3WYBKKeWvNIFQyof16xzN7qPnJk6rqTHsKyj22wGz3Z2MC6lrv72Ea4Lvt0AA\n9O8cTY05NzbGi0QBpxusOw00qpJgjHnBGJNpjMlMTExsk+CUUsqfaQKhlA8b0DmaffnFlFdWA3C4\nsIzyyhq/bYGICQumY0Swy4HU9jkgUnykhGtT7BMK7nejOlUbKwZiGqyLAZqeSlwppVSr0gRCKR/W\nv0sMNQa+O2YNnN6bb/301wQCICXe+QR7YA2g7hQT6jdjROwtLfsLvC6B2AMEiUifOuuGANs9FI9S\nSikbTSCU8mEDulhf4O48cgaAbw+dRgT6+fFcGSlxEY0qU9WV64MlXF2JCAmiU0woOQVNl7dtS8aY\nEuBd4DciEikiY4ApwCuejUwppZQmEEr5sJS4CMKDA9l51Eog1u87wYDOMXSICPZwZJ6TEhfO4cIy\nqqprHG7ff6LULyow1dUjPtIbuzABzAbCgePAG8BPjTHaAqGUUh6mCYRSPiwwQOjfJZqNBwo5W1XN\nxgOnGNUr3tNheVRqXCTVNYYjp8sbbSs5W0V+0Vm/aoEA6JkQ6Y1dmDDGnDTGXGeMiTTGpBhjXvd0\nTEoppTSBUMrnXTOwM1sOFvLepsOUV9Ywqlecp0PyqNpKTA66MdnX9fCzBKJHQiQnSio4XeZ6gj2l\nlFIKNIFQyuddf3E3AgOEBf/cSYDAiJ7+nUDY54JwVInJXoEp1Q+7MMG541dKKaVc0QRCKR+XFB3G\nlf2TKKusZsF1g4mNCPF0SB7VOSaM4EBxmEDk1M4B4V8tEN3jwgE4dKrMw5Eod2Vnw+zZkJwMy5ZZ\nP2fPttYrpVRr8486hUr5uaenDeFMWWVt9x1/FhggdO8YwYGTjb9tzy0oJSEqlKhQ//poTI613heH\nNYFoF1asgKlTobISbrwRrr8e3nkHFi2CJUtg6VKYONHTUSqlfJm2QCjlBzqEB2vyUEf3uAiHLRD7\nT5T4XQUmgJjwIKJCgzhcqAmEt8vOtpKH0lIrgbjjDmv9HXdYt0tLre3aEqGUak2aQCil/E5KXAQH\nnAyi9rcKTAAiQrfYcO3C1A5UVEBJCRhjLaNHW+vHjDm3rqTESiaUUqq1aAKhlPI7qfERnCmvorC0\nonZdWUU1R8+U7u2oPQAAIABJREFU+2ULBEC3juHaAtEOzJ1rJQh2oaH1f4K1/YEH2jYupZR/0QRC\nKeV37N256nZjsv+e6mcDqO26xYZz+JR3zUatGluxAq69tn4SUVdJCUyaBCtXtm1cSin/ogmEUsrv\npDhIIOwzMftrC0Ryx3DOlFdRVK59X7xZVBRkZVmDp8saNBiVlVnrP//c2k8ppVqLJhBKKb+T4mAy\nue+OFQHWrMz+qFtHq5SrdmPybrfcAsHBEBsLVVXWUlp67vfYWGv7rbd6OlKllC/TBEIp5XciQ4NI\niAolp+BcP5DteWdIjY8gOizYg5F5TrdYWwKhA6m92gMPWAnCzJkQEQFbt8KUKdbPiAirGlNwMNx3\nn6cjVUr5Mk0glFJ+aVC3GL49dLr29va8MwzsGuPBiDzL3gKhlZi8W1qaNc9DcTHMmweZmbBqFQwf\nDg8+aI2BWLrU2k8ppVqLJhBKKb80JDmWPceLKD5bxZnySg6cLGVg1w6eDstjEiJDCQkK0C5M7cDE\niZCeDuXlEB0NAQHWmIeyMmu9TiKnlGpt/jXdqgM1NTUUFBRQWFhIdXW1p8NRqs0EBgYSGxtLQkIC\nAQH+913C0JRYjIFvD51GxFqX7sctEAEBYqvEpAlEe5CWBgsXWotSSrU1v08gDh06hIjQo0cPgoOD\nEfuVhFI+zBhDZWUlx44d49ChQ6SkpHg6pDY3JDkWgM0HCwkOtP7u/bkLE1jjIA5pC4RSSqkmeNXX\njiJyr4hsEJGzIvKyg+3jRWSXiJSKyGoRSb3Q5ywpKaFbt26EhIRo8qD8hogQEhJCt27dKHFWUN7H\nxUWGkBIXwZq9+by94RD9O0eTFB3m6bA8SlsglFJKucOrEgggD1gAvNRwg4gkAO8CvwbigA3AWy3x\npP7YfUMp0Pf+zSNTWLv3BLuPFTFrbC9Ph+NxyR3DKSg+S3mldudUSinlnFddPRhj3jXGvAeccLD5\nh8B2Y8zbxphyYD4wRET6t2WMSinfcedlvRidFk/PhEgmD+nq6XA8zl6JKU+7MSmllHKhPY2BGAhs\nsd8wxpSISLZt/a6GO4vILGAW4Jf9u5VSTQsMEF6ZOZLyymqCA73q+xSPqJ0LorCMXok6lbFSSinH\n2tN/zCjgdIN1p4FoRzsbY14wxmQaYzITExNbPTilVPsUGCBEhran71JaT+1s1DoOQimllAttlkCI\nSJaIGCfLGjceohhoWCIlBihq+WiVUsr/dI4JIzhQyD1Z6ulQlFJKebE2SyCMMeOMMeJkudSNh9gO\nDLHfEJFIIM22Xl2g2267jWuvvbbZ9zt16hSdOnUiOzvb5X5Tp07l2WefPd/w2p3WPp9N8bfzrVpG\nUGAAKXER7Msv9nQoSimlvJhXdWESkSARCQMCgUARCRMRe9+CZcAgEfmRbZ//BrYaYxqNf/Anc+fO\n5Zprrrngx3nuued49dVXm32/J598ku9///ukpaW5jOvRRx9lwYIFnD7dsBea5e677+a+++7j+eef\nJyMjg5iYGGJiYrjkkktYvnx5s+NqylNPPcXw4cOJiYkhMTGRyZMns23bthZ7/JY6n/Pnz0dE6i2d\nO3dudL/mnm+lnOmVGMW+fP8s7auUUso9XpVAAI8AZcCDwC223x8BMMbkAz8CngBOASOBH3smTO/x\nzTffMGLEiAt+nA4dOhAbG9us+5SWlrJo0SJmzpzZZFyDBw+mV69eDi+qjTF8+OGHTJkyheTkZH77\n29+yceNGNmzYwJVXXsl1113H1q1b3YrptttuY/78+U3ul5WVxezZs1m3bh2fffYZQUFBXHXVVZw8\nedKt52lKS57Pfv36ceTIkdrl22+/bXTf5pxvpVzplRhJ7olSqmuMp0NRSinlpbwqgTDGzHfQvWl+\nne2rjDH9jTHhti5R+z0XrWdVVlYSEhLCF198weOPP46IMHDgQJf3+eKLLxg1ahRRUVF06NCBkSNH\n1n7r3rDLzbhx45g9eza/+tWvSEhIICkpiblz51JTU1O7z0cffURAQABjxoxxK64f/OAHvPHGG43i\n+uabbygvL+fSSy9lypQpTJw4kd69e9O3b1+eeOIJoqOj+eqrry7ofDX08ccfc/vttzNo0CAGDx7M\nK6+8Qn5+PmvXrnX7MdrifAIEBQXRuXPn2qVuUYDzOd9KuZKWEEVFdQ2HTuk4CKWUUo5p6REHHvtw\nOzvyzrTpc6Z3jeHRya4TgLoCAwP56quvyMzM5OuvvyYlJYXQ0FCn+1dVVTFlyhRmzpzJa6+9RmVl\nJRs3biQwMNDpfV577TXmzJnDunXr2Lx5MzfffDPDhg3jpptuAuDLL79k2LBh9WbwdhXXiBEjWLBg\nAWVlZYSHh9fe57333mPSpEkEBdV/O1ZXV/P2229TXFzM6NGj3T4356OoqIiamho6duzo1v5tdT4B\n9u3bVztb+siRI3nyySfp1cua9Ox8zrdSrvRKjARgX34JqfGRHo5GKaWUN9IEop0KCAjgyJEjREdH\nM3z48EYXnQ2dOXOGwsJCJk+eXNu/vn9/13Pwpaen85vf/AaAvn378ve//51PP/209oI3NzeXLl26\nuB1X165dqaysJC8vr96Yiffff5/HH3+89va3337LJZdcQnl5OVFRUSxbtozBgwe7cVbO35w5cxg6\ndCiXXHKJW/u31fkcOXIkL7/8Mv379+f48eMsWLCA0aNHs337duLj48/rfCvlin3+h+z8Yq7on8Tp\nskoPR6SUUsrbaALhQHNaAjxp06ZNDBkypMnkASAuLo7bbruNCRMmMH78eMaPH8+0adPo3r270/tk\nZGTUu921a1eOHz9ee7usrIxOnTq5HZf9W/CysnM15vfu3cu+ffuYMGFC7bp+/fqxefNmCgsLeeed\nd5gxYwZZWVkMGjSo0XM9+eSTPPnkk7W3z549i4jw9NNP165bsWIFl112mdPjvP/++1mzZg1r1qxx\n2YJQV1udz4kTJ9a7PWrUKHr16sWSJUu4//77geadb6WaEhcZQlxkCLuOWhWyX1yT4+GIlFJKeRuv\nGgOhmmfz5s1cdNFFbu+/ePFivv76a8aOHcsHH3xA3759+fjjj53uHxwcXO+2iNTrs5+QkMCpU6fc\njss+QLluH/733nuP8ePHExl5rqtESEgIvXv3JjMzk6eeeoqhQ4fyhz/8wWGMd999N5s3b65dfvCD\nHzRal5mZ6fQY77vvPt544w0+++yz2m5B7mqr81lXVFQUAwcO5Lvvvqtd15zzrZQ7RvSIY93eAowx\nfL4nv82fX0RCReRFEckVkSIR2SQiE5u+Z/uSnQ2zZ0NyMixbZv2cPdtar5RS3kwTiHZsy5Ytjb7V\nbsqQIUOYN28eWVlZjBs3jiVLlpz381900UXs2LHD7bi2bdtG165d633L/v7773Pddde5fJ6amhrO\nnj3rcFtcXBy9e/euXaKjoxutc9b/f86cObz++ut89tlnTXY/cqYtzmdd5eXl7Nq1q15Xp+acb6Xc\ncVnfBPJOl7Mh9xRbDxV6IoQg4CBwOdAB+DXwDxHp4YlgWsOKFZCRAYsWwRVXwPXXw7hx1u2MDGu7\nUkp5K00g2rGqqip27dpFXl4ehYXWP/mFCxc6vBjOycnhwQcfZN26deTm5rJ69Wq2bt1Kenr6eT//\nhAkT2LlzJydOnGgyLrAGCdedqyA/P5/169czefLk2nUPPvggX375Jfv37+fbb7/loYceIisri+nT\np593nI7cc889LF68mDfeeIOOHTty9OhRjh49SnHxuQm0nJ1LaLvzOXfuXD7//HNycnL4+uuvmTp1\nKiUlJcyYMaN2H3fPt1LuGtvHarV68qOdGA9UczXGlNiq8u03xtQYY/4J5ADD2j6alpedDVOnQmkp\nVFbCHXdY6++4w7pdWmpt15YIpZS30gSiHXviiSd48803SU5O5qGHHgKgoKCA3bt3N9o3IiKCPXv2\nMG3aNPr27cuMGTOYPn068+bNO+/nHzx4MCNGjODNN99sMq7y8nKWLVvGnXfeWbvfhx9+yPDhw+t9\nQ3706FFuueUW+vXrx/jx4/nmm29YsWJFo7EAF+ovf/kLRUVFjB8/ni5dutQudcdOODuX0Hbn89Ch\nQ9x0003069ePH/7wh4SGhrJ+/XpSU1Nr93H3fCvlru5xEfRMiGTTgUI6RgQ3fYdWJiKdgL7Adk/H\n0hIqKqCkBIyxFnuRuTFjzq0rKbGSCaWU8kZiPPH1UhvLzMw0GzZscLht586dDBgwoI0j8h0rV65k\nzpw57Nixw+UA5Oeff57333+ff/3rX7XrpkyZwpgxY/jlL3/ZFqG2C+6ez6Y4Ot/O6N+AcmR73mn+\nnXOS9C4xjEpL+I8xxvlgolYkIsHACiDbGHOXk31mAbMAUlJShuXm5rZhhM03aRL84x8Q6aJKbkkJ\n3HADLF/ednEppZSIuPV5ry0Q6oJcc8013HPPPRw6dMjlfsHBwfz5z3+ut27MmDG1JUyVxd3z2RRH\n51up5hjYtQO3j+nJyF7xLf7YIpIlIsbJsqbOfgHAK0AFcK+zxzPGvGCMyTTGZLaHogErVsC111pJ\ngiMlJVaSsXJl28allFLu0hYI/fZV+Tn9G1BNcfcbqRZ+TgFeAnoA3zfGuFWP2NXnvbeIiYGiIitJ\nePttqFvnoawMpk2zWh5iYuD0ac/FqZTyP9oCoZRSqj37KzAAmOxu8tBe3HILBAdDbCxUVVlLaem5\n32Njre233urpSJVSyjFNIJRSSnkVEUkF7gKGAkdFpNi2tGw5Ng954AErQZg5EyIiYOtWmDLF+hkR\nYVVjCg6G++7zdKRKKeWYzkStlFLKqxhjcgFpcsd2Ki0Nli6F4mKYNw+efdaqvDR8ONx/P4wda21P\nS/N0pEop5Zi2QCillFJtbOJESE+H8nKIjoaAAIiKssZApKdb25VSyltpC4RSSinlAWlpsHChtSil\nVHuiLRBKKaWUUkopt2kCoZRSSimllHKbJhDqgtx2221ce+21zbrPuHHjuPdep3NCtZj58+czaNCg\nVn8epZRSSil/oglEO7dp0yYCAwMZM2aMW/ufzwW/K8899xyvvvpqs+7z7rvv8tRTT7VYDM7MnTuX\nzz//vMUe7+WXXyYqKqrFHk8ppZRSqj3SBKKd+/vf/87s2bPZtm0bO3fubLHHraysdGu/Dh06EBsb\n26zHjouLIzo6+nzCapaoqCji4+Nb/XmUUkoppfyJJhDtWFlZGa+//jp33nknU6dO5cUXX3S5//z5\n81myZAnLly9HRBARsrKy2L9/PyLCG2+8wZVXXkl4eDj/+7//y4kTJ7jppptITk4mPDycgQMHsnjx\n4nqP2bBFY9y4ccyePZtf/epXJCQkkJSUxNy5c6mpqam3T90uTD169GDBggXcddddxMTEkJyczO9/\n//t6z7Nnzx4uv/xywsLC6NevHx999BFRUVG8/PLLLo+3bhcme6zPPfcc3bp1o2PHjtx+++2UlpbW\n7vPFF18watQooqKi6NChAyNHjmTbtm1kZWVx++23U1JSUnvu5s+fD8Crr77K8OHDiY6OJikpiWnT\npnH48OHax8zKykJE+PTTTxk5ciQRERFkZmaycePGevGuX7+eK6+8ksjISDp06MD48ePJy8sDwBjD\n7373O9LS0ggPD2fw4MHNbvlRSimllGoJmkA4IOK5pTmWLl1KamoqGRkZ3Hrrrfzf//2fy5aDuXPn\ncsMNN3DVVVdx5MgRjhw5wujRo2u3P/TQQ8yePZsdO3Zw3XXXUV5ezsUXX8w///lPtm/fzpw5c7jr\nrrv49NNPXcb12muvERQUxLp161i4cCF//OMfeeutt1ze5w9/+AODBw9m48aNzJs3j1/+8pd89dVX\nANTU1HD99dcTFBTE+vXrefnll3nsscc4e/ZsM86W5csvv2Tbtm2sWrWKt956i2XLlvHcc88BUFVV\nxZQpU7j00kvZsmULX3/9NXPmzCEwMJDRo0fzxz/+kYiIiNpzN3fuXAAqKip47LHH2LJlC//85z8p\nKCjgpptuavTcDz30EP/zP//Dxo0biY+PZ/r06RhjANiyZQtXXHEFvXv3Zu3ataxfv54bbriBqqoq\nAB555BFefPFFnn/+eXbs2MFDDz3EXXfdxfLly5t9DpRSLSc7G2bPhuRkWLbM+jl7trVeKaV8ljHG\n55dhw4YZZ3bs2NFonTUnqGeW5hg7dqz5/e9/b4wxpqamxqSmppqlS5e6vM+MGTPMpEmT6q3Lyckx\ngHn66aebfM4bb7zRzJw50+njXX755WbUqFH17nPVVVfVu8/ll19u7rnnntrbqamp5sc//nG9+/Tu\n3ds8/vjjxhhjVq5caQIDA82hQ4dqt69du9YAZvHixU5jffTRR83AgQPrxZqcnGwqKytr1/3Xf/2X\nGT9+vDHGmBMnThjAZGVlOXy8xYsXm8jISKfPZ7dz504DmIMHDxpjjFm9erUBzMqVK2v3WbNmTb19\nbr75ZjNy5EiHj1dcXGzCwsLMF198UW/9nDlzzMSJE5uMpymO/gaUqgvYYLzgs9ydxdXnfUv76CNj\nIiKMCQ425pZbrHXTp1u3IyKs7Uop1Z64+3mvLRDt1N69e1m7di0333wzACLC9OnTWbRo0Xk/ZmZm\nZr3b1dXVPPHEE2RkZBAfH09UVBTvvvsuBw4ccPk4GRkZ9W537dqV48ePn/d9du3aRdeuXenWrVvt\n9uHDhxMQ0Py3b3p6OkFB5+ZPrPs8cXFx3HbbbUyYMIFJkybx7LPPcvDgwSYfc+PGjUyZMoXU1FSi\no6Nrz2PD81T3GLt27QpQ+9ybNm1i/PjxDh9/x44dlJeXc8011xAVFVW7/PWvfyVbv+ZUyiOys2Hq\nVCgthcpKuOMOa/0dd1i3S0ut7fonqpTyRToTtQPGeDqCpi1atIjq6mpSUlJq1xlb4AcPHqR79+7N\nfszIyMh6t59++mmeeeYZnnvuOQYPHkxUVBS/+tWvmkwGgoOD690WkXpjIJp7H2MM0tz+XecZ2+LF\ni/n5z3/OypUr+eCDD3j44Yd57733mDBhgsPHKykpYcKECVx11VW88sorJCUlUVBQwGWXXUZFRYXT\n57YfT91jdMa+z4cffljv9XZ0PEqptlFRASUl527be1SOGVP/f8iuXW0bl1JKtQVtgWiHqqqqWLJk\nCU899RSbN2+uXbZs2UJGRkajgc51hYSEUF1d7dbzrFmzhsmTJ3PrrbcydOhQ0tLS2LNnT0sdhtsG\nDBjA4cOHawcUA2zYsKHJpOR8DRkyhHnz5pGVlcW4ceNYsmQJ4Pjc7dq1i4KCAp588knGjh1L//79\nm0ywHLn44ov57LPPHG5LT08nNDSU3NxcevfuXW9JTU1t/gEqpS7Y3Ln1E4jQ0Po/wdr+wANtG5dS\nSrUFr0ogROReEdkgImdF5OUG23qIiBGR4jrLrz0UqkctX76cgoIC7rzzTgYNGlRv+fGPf8xLL73k\n9OK6R48ebNu2jd27d1NQUOBy0HXfvn359NNPWbNmDbt27eLee+8lJyentQ7Lqauvvpp+/foxY8YM\ntmzZwvr167n//vsJCgpqsZYJgJycHB588EHWrVtHbm4uq1evZuvWraSnpwPWuSsvL+eTTz6hoKCA\n0tJSUlJSCA0NZeHChezbt4/ly5fz6183/235i1/8gk2bNjFr1iy2bNnC7t27WbRoEQcOHCA6Opq5\nc+cyd+5cXnrpJfbu3cvmzZv529/+xgsvvNBix6+Uct+KFXDttfWTiLpKSmDSJFi5sm3jUkqptuBV\nCQSQBywAXnKxT6wxJsq2PN5GcXmVF198kSuuuMLhHAfTpk0jNzeXVatWObzvnXfeyYABA8jMzCQx\nMZG1a9c6fZ5HHnmEESNGMHHiRMaOHUtkZCTTp09vseNwV0BAAMuWLePs2bOMGDGCGTNm8PDDDyMi\nhIWFtdjzREREsGfPHqZNm0bfvn2ZMWMG06dPZ968eQCMHj2au+++m5tuuonExER+97vfkZiYyJIl\nS3jvvfdIT0/nscce49lnn232cw8dOpRVq1axa9cuRo0axciRI3nzzTdruyg9/vjjzJ8/n6effpqB\nAwdy9dVX884779CzZ88WO36llPuioiArC268EcrK6m8rK7PWf/65tZ9SSvkacdX32lNEZAGQbIy5\nrc66HkAOEGyMqWrO42VmZpoNGzY43LZz504GDBhw3rEqz9iyZQtDhw5lw4YNDBs2zNPhtGv6N6Ca\nIiL/McZkNr2n57n6vHcmOxueeQZefRWKi62L/ltusbofpaU5vs/s2bBoEdxwA/z1rxAebo2LCAmx\nEoif/hT+8Q+YNQsWLmyBA1NKqTbg7ue9t7VAuCNXRA6JyGIRSXC2k4jMsnWH2pCfn9+W8alWsGzZ\nMv71r3+Rk5PD6tWrue222xgyZAgXX3yxp0NTSrVjK1ZARoaVDBQVWQOgi4qs2xkZ1nZHHngAgoNh\n5kyIiICtW2HKFOtnRIRVjSk4GO67r22PRyml2kJ7SiAKgOFAKjAMiAZec7azMeYFY0ymMSYzMTGx\njUJUraWoqIh7772X9PR0pk+fzoABA/j4449bdAyEUsq/NCzFWldTpVjT0mDpUqvFYt48yMyEVatg\n+HB48EFrDMTSpc5bMJRSqj1rswRCRLJsg6AdLWuaur8xptgYs8EYU2WMOQbcC3xPRGJaP3rlaT/5\nyU/Ys2cPZWVl5OXl8frrr9OpUydPh6WUaseeeaZx4tBQZSX84Q+Ot02cCOnpUF4O0dEQEGB1fyor\ns9ZPnNjyMSullDdos3kgjDHjWvohbT/1K2illFLN9uqr7iUQr7zifBxDWpq1Tcc5KKX8iVd1YRKR\nIBEJAwKBQBEJE5Eg27aRItJPRAJEJB74E5BljDl9oc/rjQPJlWoL+t5X/qy4uGX3U0opf+FVCQTw\nCFAGPAjcYvv9Edu2XsBKoAjYBpwFbrrQJwwODqasYQ0+pfxEWVmZzmat/Ja7JVa1FKtSStXnVQmE\nMWa+MUYaLPNt294wxvQ0xkQaY7oYY35ijDl6oc+ZlJTE4cOHKS0t1W9jld8wxlBaWsrhw4dJSkry\ndDhKecQtt1iVklwJDoZbb22beJRSqr1oszEQ3iomxhqDnZeX53JWZqV8TXBwMJ06dar9G1DK3zzw\nACxZ4nochJZiVUqpxvw+gQAridCLKKWU8i/2UqxTp1pJRN1EIjjYWrQUq1JKNeZVXZiUUkqptjRx\nojX526xZEBNjlWKNibFub92qpViVUsoRbYFQSinl17QUq1JKNY+2QCillFJKKaXcpgmEUkoppZRS\nym2aQCillFJKKaXcJv4w94GIFAG7PR1HK0oACjwdRCvz9WPU42vffP34+hljoj0dhDtEJB/I9XQc\nbcTX33ctQc9R0/QcNc2fzlGqMSaxqZ38ZRD1bmNMpqeDaC0issGXjw98/xj1+No3fzg+T8fgLnf+\n8fkKX3/ftQQ9R03Tc9Q0PUeNaRcmpZRSSimllNs0gVBKKaWUUkq5zV8SiBc8HUAr8/XjA98/Rj2+\n9k2PT3mCvi5N03PUND1HTdNz1IBfDKJWSimllFJKtQx/aYFQSimllFJKtQBNIJRSSimllFJu0wRC\nKaWUUkop5TafTiBEJE5ElolIiYjkisjNno6ppYlIloiUi0ixbWm3E+aJyL0iskFEzorIyw22jReR\nXSJSKiKrRSTVQ2FeEGfHKCI9RMTUeR2LReTXHgy12UQkVERetP2tFYnIJhGZWGd7u34NXR2fL7x+\ndiLyqogcEZEzIrJHRP6rzrZ2/Rp6OxefD6NE5BMROSki+SLytoh0cfE4PvN/oSEX5yjdtv6UbVkl\nIukuHsdnrw9a8Bz53fuowT6P2j7Xr3LxOD1sn4Wlts9Gp/v6Gp9OIIDngQqgEzAd+KuIDPRsSK3i\nXmNMlG3p5+lgLkAesAB4qe5KEUkA3gV+DcQBG4C32jy6luHwGOuIrfNaPt6GcbWEIOAgcDnQAev1\n+oftA9YXXkOnx1dnn/b8+tk9BfQwxsQAPwAWiMgwH3kNvZ2zz4eOWFVgegCpQBGwuInH8pX/Cw05\nO0d5wFSs92YC8AHwpovH8eXrg5Y6R+B/7yMARCQN61wdaeJx3gA2AfHAw8BSEfGLySx9diZqEYkE\nfgQMMsYUA2tE5APgVuBBjwanHDLGvAsgIplAcp1NPwS2G2Petm2fDxSISH9jzK42D/QCuDjGds8Y\nUwLMr7PqnyKSAwzD+nBt169hE8f3H48E1QqMMdvr3rQtaVjH2a5fQ2/n7PPBGLOi7n4ishD4vG2j\n8w4uzlEhUGjbJkA10NvRY/j69UFLnCNf58b/4oXAPOAvzh5DRPoCFwPfM8aUAe+IyM+x3lt/a/Gg\nvYwvt0D0BaqNMXvqrNsC+Mo3DHU9JSIFIrJWRMZ5OphWMBDrtQNqL+Sy8c3XMldEDonIYts3vu2W\niHTC+jvcjg++hg2Oz84nXj8R+YuIlAK7sL6B+wgffA3bsbHUf9854uv/FxwSkUKgHPgz8KST3fzp\n+qARN8+Rnd+9j0RkGlBhjPmoiV0HAvuMMUV11vnN+8iXE4go4HSDdaeBaA/E0prmAb2AblhN3B/a\nmt58iT+8lgXAcKzuCcOwju01j0Z0AUQkGCv+JbZvp33qNXRwfD71+hljZmMdw2VY3ZbO4mOvYXsl\nIhnAfwO/cLGbP/xfcMgYE4vVxfBerK4ljvj1e9nNcwR++D4SkSispOrnbuzu1+8jX04gioGYButi\nsPqO+gxjzNfGmCJjzFljzBJgLfB9T8fVwnz+tTTGFBtjNhhjqowxx7A+2L8nIg2P2+uJSADwClb/\n4nttq33mNXR0fL70+tkZY6qNMWuwmvd/ig+9hu2ViPQGVgBzjDFfOtvPT/4vOGVrHfsb8H8ikuRg\nF79/L7txjvz1ffQY8IoxJseNff36feTLCcQeIEhE+tRZN4Smm33bOwOIp4NoYduxXjugtv9qGr79\nWtqniG/Ohcn6AAAEdUlEQVRXr6WtX+2LWAMTf2SMqbRt8onX0MXxNdQuXz8ngjj3WrX717C9Eqvi\n1SrgcWPMK828uy/+X2hKABCB9e15Q/56fdCQq3PkiD+8j8YDPxORoyJyFOiOVSxjnoN9twO9RKRu\ni4PfvI98NoGwZdfvAr8RkUgRGQNMwfrm0CeISKyITBCRMBEJEpHpWH1jP/Z0bOfDdgxhQCAQaD8u\nYBkwSER+ZNv+38DW9jhw09kxishIEeknIgEiEg/8CcgyxjRsHvV2fwUGAJNtg8rsfOU1dHh8vvL6\niUiSiPxYRKJEJFBEJgA3AZ/hO6+h13Lx+dAN6zV43hjjcnCmr/1faMjFObpaRC6yvW9jgGeBU8DO\nho/h69cHLXGO/PV9hJVADAKG2pY84C6sql312MbQbAYetd3/eiADeKeNDsOzjDE+u2CVKnsPKAEO\nADd7OqYWPr5E4Bus5rJCYD1wtafjuoDjmc+5qi/2Zb5t21VYAzrLgCysMpMej7mljhHrIi3H9l49\nAvwf0NnT8Tbz2FJtx1OO1bRrX6b7wmvo6vh84fWzHWMiVnWfQuAM8C1wZ53t7fo19PbFxefDo7bf\n677viuvc71fAijqvoc/8X2jGOZpme28WA/lYA/8zHJ0j222fvT5oiXPkr+8jB/vtB66qc/tvwN/q\n3O5h+ywsA3bX3dfXF7GdAKWUUkoppZRqks92YVJKKaWUUkq1PE0glFJKKaWUUm7TBEIppZRSSinl\nNk0glFJKKaWUUm7TBEIppZRSSinlNk0glFJKKaWUUm7TBEKpNiAiRkSmejoOpZRSrUs/75U/0ARC\nqQtg+0fhannZtmsX4EMPhqqUUuoC6Oe9UufoRHJKXQAR6Vzn5rXA37H+ediVGWNOt21USimlWpp+\n3it1jrZAKHUBjDFH7QtQ2HCd/Z9J3SZtEelhu/1jEflcRMpEZJOIZIjIIBFZJyIlIrJGRHrWfT4R\nmSwi/xGRchHJEZEnRCSkzQ9cKaX8jH7eK3WOJhBKec5jwG+Bi7D+Gb0O/Bl4GBgBhAF/su8sIhOA\n14CFwEDgDmAq8GSbRq2UUqq59PNe+RRNIJTynGeNMR8ZY3YBz2D9k/izMWa1MWY71j+OK+rs/zDw\ne2PMYmNMtjFmNTAPuFtEpM2jV0op5S79vFc+JcjTASjlx7bW+f2Y7ee3DdZFikiEMaYUGAaMEJF5\ndfYJAMKBzsCR1gxWKaXUedPPe+VTNIFQynMq6/xuXKwLqPPzMeBtB4+V37KhKaWUakH6ea98iiYQ\nSrUfG4H+xpi9ng5EKaVUq9LPe+XVNIFQqv34DfBPEckF/gFUAYOAEcaYX3o0MqWUUi1JP++VV9NB\n1Eq1E8aYj4FJWAPt/m1bHgQOeDIupZRSLUs/75W304nklFJKKaWUUm7TFgillFJKKaWU2zSBUEop\npZRSSrlNEwillFJKKaWU2zSBUEoppZRSSrlNEwillFJKKaWU2zSBUEoppZRSSrlNEwillFJKKaWU\n2zSBUEoppZRSSrnt/wMowZaf9xPuDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181b183438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))\n",
    "\n",
    "n_steps = 20\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"A time series (generated)\", fontsize=14)\n",
    "plt.plot(t, time_series(t), label=r\"$t . \\sin(t) / 3 + 2 . \\sin(5t)$\")\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"b-\", linewidth=3, label=\"A training instance\")\n",
    "plt.legend(loc=\"lower left\", fontsize=14)\n",
    "plt.axis([0, 30, -17, 13])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"A training instance\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "\n",
    "save_fig(\"time_series_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next_batch(1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.c_[X_batch[0], y_batch[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an `OuputProjectionWrapper`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the RNN. It will contain 100 recurrent neurons and we will unroll it over 20 time steps since each traiing instance will be 20 inputs long. Each input will contain only one feature (the value at that time). The targets are also sequences of 20 inputs, each containing a sigle value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time step we now have an output vector of size 100. But what we actually want is a single output value at each time step. The simplest solution is to wrap the cell in an `OutputProjectionWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "    output_size=n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "    \n",
    "    saver.save(sess, \"./my_time_series_model\") # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                          # not shown in the book\n",
    "    saver.restore(sess, \"./my_time_series_model\")   # not shown\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "save_fig(\"time_series_pred_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using an `OutputProjectionWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_outputs = 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "    \n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})\n",
    "    \n",
    "    saver.save(sess, \"./my_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a creative new sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                        # not shown in the book\n",
    "    saver.restore(sess, \"./my_time_series_model\") # not shown\n",
    "\n",
    "    sequence = [0.] * n_steps\n",
    "    for iteration in range(300):\n",
    "        X_batch = np.array(sequence[-n_steps:]).reshape(1, n_steps, 1)\n",
    "        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "        sequence.append(y_pred[0, -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(np.arange(len(sequence)), sequence, \"b-\")\n",
    "plt.plot(t[:n_steps], sequence[:n_steps], \"b-\", linewidth=3)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_time_series_model\")\n",
    "\n",
    "    sequence1 = [0. for i in range(n_steps)]\n",
    "    for iteration in range(len(t) - n_steps):\n",
    "        X_batch = np.array(sequence1[-n_steps:]).reshape(1, n_steps, 1)\n",
    "        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "        sequence1.append(y_pred[0, -1, 0])\n",
    "\n",
    "    sequence2 = [time_series(i * resolution + t_min + (t_max-t_min/3)) for i in range(n_steps)]\n",
    "    for iteration in range(len(t) - n_steps):\n",
    "        X_batch = np.array(sequence2[-n_steps:]).reshape(1, n_steps, 1)\n",
    "        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "        sequence2.append(y_pred[0, -1, 0])\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, sequence1, \"b-\")\n",
    "plt.plot(t[:n_steps], sequence1[:n_steps], \"b-\", linewidth=3)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(t, sequence2, \"b-\")\n",
    "plt.plot(t[:n_steps], sequence2[:n_steps], \"b-\", linewidth=3)\n",
    "plt.xlabel(\"Time\")\n",
    "save_fig(\"creative_sequence_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_steps = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "          for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.random.rand(2, n_steps, n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributing a Deep RNN Across Multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do **NOT** do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):  # BAD! This is ignored.\n",
    "    layer1 = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "with tf.device(\"/gpu:1\"):  # BAD! Ignored again.\n",
    "    layer2 = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, you need a `DeviceCellWrapper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DeviceCellWrapper(tf.contrib.rnn.RNNCell):\n",
    "  def __init__(self, device, cell):\n",
    "    self._cell = cell\n",
    "    self._device = device\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._cell.state_size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._cell.output_size\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    with tf.device(self._device):\n",
    "        return self._cell(inputs, state, scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 5\n",
    "n_steps = 20\n",
    "n_neurons = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devices = [\"/cpu:0\", \"/cpu:0\", \"/cpu:0\"] # replace with [\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"] if you have 3 GPUs\n",
    "cells = [DeviceCellWrapper(dev,tf.contrib.rnn.BasicRNNCell(num_units=n_neurons))\n",
    "         for dev in devices]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, since TensorFlow 1.1, you can use the `tf.contrib.rnn.DeviceWrapper` class (alias `tf.nn.rnn_cell.DeviceWrapper` since TF 1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(sess.run(outputs, feed_dict={X: np.random.rand(2, n_steps, n_inputs)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "n_steps = 20\n",
    "n_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `input_keep_prob` parameter can be a placeholder, making it possible to set it to any value you want during training, and to 1.0 during testing (effectively turning dropout off). This is a much more elegant solution than what was recommended in earlier versions of the book (i.e., writing your own wrapper class or having a separate model for training and testing). Thanks to Shen Cheng for bringing this to my attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "cells = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "         for layer in range(n_layers)]\n",
    "cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "              for cell in cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells_drop)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "train_keep_prob = 0.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        _, mse = sess.run([training_op, loss],\n",
    "                          feed_dict={X: X_batch, y: y_batch,\n",
    "                                     keep_prob: train_keep_prob})\n",
    "        if iteration % 100 == 0:                   # not shown in the book\n",
    "            print(iteration, \"Training MSE:\", mse) # not shown\n",
    "    \n",
    "    saver.save(sess, \"./my_dropout_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_dropout_time_series_model\")\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, it seems that Dropout does not help at all in this particular case. :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "n_layers = 3\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_layer_h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((batch_size, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(\"Epoch\", epoch, \"Train accuracy =\", acc_train, \"Test accuracy =\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units=n_neurons, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is based on TensorFlow's [Word2Vec tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/word2vec/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "WORDS_PATH = \"datasets/words\"\n",
    "WORDS_URL = 'http://mattmahoney.net/dc/text8.zip'\n",
    "\n",
    "def mkdir_p(path):\n",
    "    \"\"\"Create directories, ok if they already exist.\n",
    "    \n",
    "    This is for python 2 support. In python >=3.2, simply use:\n",
    "    >>> os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def fetch_words_data(words_url=WORDS_URL, words_path=WORDS_PATH):\n",
    "    os.makedirs(words_path, exist_ok=True)\n",
    "    zip_path = os.path.join(words_path, \"words.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        urllib.request.urlretrieve(words_url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path) as f:\n",
    "        data = f.read(f.namelist()[0])\n",
    "    return data.decode(\"ascii\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = fetch_words_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary_size = 50000\n",
    "\n",
    "vocabulary = [(\"UNK\", None)] + Counter(words).most_common(vocabulary_size - 1)\n",
    "vocabulary = np.array([word for word, _ in vocabulary])\n",
    "dictionary = {word: code for code, word in enumerate(vocabulary)}\n",
    "data = np.array([dictionary.get(word, 0) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\" \".join(words[:9]), data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\" \".join([vocabulary[word_index] for word_index in [5241, 3081, 12, 6, 195, 2, 3134, 46, 59]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words[24], data[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_index=0\n",
    "batch, labels = generate_batch(8, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch, [vocabulary[word] for word in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels, [vocabulary[word] for word in labels[:, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128  # Dimension of the embedding vector.\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# Input data.\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "embedding_size = 150\n",
    "\n",
    "# Look up embeddings for inputs.\n",
    "init_embeds = tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)\n",
    "embeddings = tf.Variable(init_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs = tf.placeholder(tf.int32, shape=[None])\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the variables for the NCE loss\n",
    "nce_weights = tf.Variable(\n",
    "    tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                        stddev=1.0 / np.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "# Compute the average NCE loss for the batch.\n",
    "# tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "# time we evaluate the loss.\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.nce_loss(nce_weights, nce_biases, train_labels, embed,\n",
    "                   num_sampled, vocabulary_size))\n",
    "\n",
    "# Construct the Adam optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), axis=1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "# Add variable initializer.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        print(\"\\rIteration: {}\".format(step), end=\"\\t\")\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "        feed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}\n",
    "\n",
    "        # We perform one update step by evaluating the training op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        _, loss_val = session.run([training_op, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print(\"Average loss at step \", step, \": \", average_loss)\n",
    "            average_loss = 0\n",
    "\n",
    "        # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in range(valid_size):\n",
    "                valid_word = vocabulary[valid_examples[i]]\n",
    "                top_k = 8 # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                log_str = \"Nearest to %s:\" % valid_word\n",
    "                for k in range(top_k):\n",
    "                    close_word = vocabulary[nearest[k]]\n",
    "                    log_str = \"%s %s,\" % (log_str, close_word)\n",
    "                print(log_str)\n",
    "\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the final embeddings (of course you can use a TensorFlow `Saver` if you prefer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./my_final_embeddings.npy\", final_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  #in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])\n",
    "labels = [vocabulary[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `basic_rnn_seq2seq()` function creates a simple Encoder/Decoder model: it first runs an RNN to encode `encoder_inputs` into a state vector, then runs a decoder initialized with the last encoder state on `decoder_inputs`. Encoder and decoder use the same RNN cell type but they don't share parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "reset_graph()\n",
    "\n",
    "n_steps = 50\n",
    "n_neurons = 200\n",
    "n_layers = 3\n",
    "num_encoder_symbols = 20000\n",
    "num_decoder_symbols = 20000\n",
    "embedding_size = 150\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, n_steps]) # English sentences\n",
    "Y = tf.placeholder(tf.int32, [None, n_steps]) # French translations\n",
    "W = tf.placeholder(tf.float32, [None, n_steps - 1, 1])\n",
    "Y_input = Y[:, :-1]\n",
    "Y_target = Y[:, 1:]\n",
    "\n",
    "encoder_inputs = tf.unstack(tf.transpose(X)) # list of 1D tensors\n",
    "decoder_inputs = tf.unstack(tf.transpose(Y_input)) # list of 1D tensors\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "\n",
    "output_seqs, states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "    encoder_inputs,\n",
    "    decoder_inputs,\n",
    "    cell,\n",
    "    num_encoder_symbols,\n",
    "    num_decoder_symbols,\n",
    "    embedding_size)\n",
    "\n",
    "logits = tf.transpose(tf.unstack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits_flat = tf.reshape(logits, [-1, num_decoder_symbols])\n",
    "Y_target_flat = tf.reshape(Y_target, [-1])\n",
    "W_flat = tf.reshape(W, [-1])\n",
    "xentropy = W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y_target_flat, logits=logits_flat)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embedded Reber Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build a function that generates strings based on a grammar. The grammar will be represented as a list of possible transitions for each state. A transition specifies the string to output (or a grammar to generate it) and the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice, seed\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "default_reber_grammar = [\n",
    "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
    "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
    "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
    "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
    "    [(\"X\", 3), (\"S\", 6)],\n",
    "    [(\"P\", 4), (\"V\", 6)],\n",
    "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
    "\n",
    "embedded_reber_grammar = [\n",
    "    [(\"B\", 1)],\n",
    "    [(\"T\", 2), (\"P\", 3)],\n",
    "    [(default_reber_grammar, 4)],\n",
    "    [(default_reber_grammar, 5)],\n",
    "    [(\"T\", 6)],\n",
    "    [(\"P\", 6)],\n",
    "    [(\"E\", None)]]\n",
    "\n",
    "def generate_string(grammar):\n",
    "    state = 0\n",
    "    output = []\n",
    "    while state is not None:\n",
    "        production, state = choice(grammar[state])\n",
    "        if isinstance(production, list):\n",
    "            production = generate_string(grammar=production)\n",
    "        output.append(production)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a few strings based on the default Reber grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    print(generate_string(default_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's generate a few strings based on the embedded Reber grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    print(generate_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need a function to generate strings that do not respect the grammar. We could generate a random string, but the task would be a bit too easy, so instead we will generate a string that respects the grammar, and we will corrupt it by changing just one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_corrupted_string(grammar, chars=\"BEPSTVX\"):\n",
    "    good_string = generate_string(grammar)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = choice(list(set(chars) - set(good_char)))\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few corrupted strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not possible to feed a string directly to an RNN: we need to convert it to a sequence of vectors, first. Each vector will represent a single letter, using a one-hot encoding. For example, the letter \"B\" will be represented as the vector `[1, 0, 0, 0, 0, 0, 0]`, the letter E will be represented as `[0, 1, 0, 0, 0, 0, 0]` and so on. Let's write a function that converts a string to a sequence of such one-hot vectors. Note that if the string is shorted than `n_steps`, it will be padded with zero vectors (later, we will tell TensorFlow how long each string actually is using the `sequence_length` parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_one_hot_vectors(string, n_steps, chars=\"BEPSTVX\"):\n",
    "    char_to_index = {char: index for index, char in enumerate(chars)}\n",
    "    output = np.zeros((n_steps, len(chars)), dtype=np.int32)\n",
    "    for index, char in enumerate(string):\n",
    "        output[index, char_to_index[char]] = 1.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string_to_one_hot_vectors(\"BTBTXSETE\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate the dataset, with 50% good strings, and 50% bad strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(size):\n",
    "    good_strings = [generate_string(embedded_reber_grammar)\n",
    "                    for _ in range(size // 2)]\n",
    "    bad_strings = [generate_corrupted_string(embedded_reber_grammar)\n",
    "                   for _ in range(size - size // 2)]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    n_steps = max([len(string) for string in all_strings])\n",
    "    X = np.array([string_to_one_hot_vectors(string, n_steps)\n",
    "                  for string in all_strings])\n",
    "    seq_length = np.array([len(string) for string in all_strings])\n",
    "    y = np.array([[1] for _ in range(len(good_strings))] +\n",
    "                 [[0] for _ in range(len(bad_strings))])\n",
    "    rnd_idx = np.random.permutation(size)\n",
    "    return X[rnd_idx], seq_length[rnd_idx], y[rnd_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, l_train, y_train = generate_dataset(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's padded with a lot of zeros because the longest string in the dataset is that long. How long is this particular string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What class is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We are ready to create the RNN to identify good strings. We build a sequence classifier very similar to the one we built earlier to classify MNIST images, with two main differences:\n",
    "* First, the input strings have variable length, so we need to specify the `sequence_length` when calling the `dynamic_rnn()` function.\n",
    "* Second, this is a binary classifier, so we only need one output neuron that will output, for each input string, the estimated log probability that it is a good string. For multiclass classification, we used `sparse_softmax_cross_entropy_with_logits()` but for binary classification we use `sigmoid_cross_entropy_with_logits()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "possible_chars = \"BEPSTVX\"\n",
    "n_inputs = len(possible_chars)\n",
    "n_neurons = 30\n",
    "n_outputs = 1\n",
    "\n",
    "learning_rate = 0.02\n",
    "momentum = 0.95\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, None, n_inputs], name=\"X\")\n",
    "seq_length = tf.placeholder(tf.int32, [None], name=\"seq_length\")\n",
    "y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "gru_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(gru_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs, name=\"logits\")\n",
    "y_pred = tf.cast(tf.greater(logits, 0.), tf.float32, name=\"y_pred\")\n",
    "y_proba = tf.nn.sigmoid(logits, name=\"y_proba\")\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=momentum,\n",
    "                                       use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.equal(y_pred, y, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a validation set so we can track progress during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, l_val, y_val = generate_dataset(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        X_batches = np.array_split(X_train, len(X_train) // batch_size)\n",
    "        l_batches = np.array_split(l_train, len(l_train) // batch_size)\n",
    "        y_batches = np.array_split(y_train, len(y_train) // batch_size)\n",
    "        for X_batch, l_batch, y_batch in zip(X_batches, l_batches, y_batches):\n",
    "            loss_val, _ = sess.run(\n",
    "                [loss, training_op],\n",
    "                feed_dict={X: X_batch, seq_length: l_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, seq_length: l_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, seq_length: l_val, y: y_val})\n",
    "        print(\"{:4d}  Train loss: {:.4f}, accuracy: {:.2f}%  Validation accuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, 100 * acc_train, 100 * acc_val))\n",
    "        saver.save(sess, \"my_reber_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our RNN on two tricky strings: the first one is bad while the second one is good. They only differ by the second to last character. If the RNN gets this right, it shows that it managed to notice the pattern that the second letter should always be equal to the second to last letter. That requires a fairly long short-term memory (which is the reason why we used a GRU cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = [\n",
    "    \"BPBTSSSSSSSSSSSSXXTTTTTVPXTTVPXTTTTTTTVPXVPXVPXTTTVVETE\",\n",
    "    \"BPBTSSSSSSSSSSSSXXTTTTTVPXTTVPXTTTTTTTVPXVPXVPXTTTVVEPE\"]\n",
    "l_test = np.array([len(s) for s in test_strings])\n",
    "max_length = l_test.max()\n",
    "X_test = [string_to_one_hot_vectors(s, n_steps=max_length)\n",
    "          for s in test_strings]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"my_reber_classifier\")\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, seq_length: l_test})\n",
    "\n",
    "print()\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, y_proba_val[index][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta-da! It worked fine. The RNN found the correct answers with absolute confidence. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. and 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming soon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
